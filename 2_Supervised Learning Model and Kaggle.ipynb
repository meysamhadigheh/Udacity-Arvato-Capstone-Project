{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from xgboost) (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from bayesian-optimization) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from bayesian-optimization) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from bayesian-optimization) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from lightgbm) (1.5.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize==0.8.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (0.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-optimize==0.8.1) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-optimize==0.8.1) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-optimize==0.8.1) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-optimize==0.8.1) (1.19.5)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-optimize==0.8.1) (21.8.3)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pyaml>=16.9->scikit-optimize==0.8.1) (5.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn>=0.20.0->scikit-optimize==0.8.1) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.23.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn==0.23.2) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn==0.23.2) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn==0.23.2) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from scikit-learn==0.23.2) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (0.26.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (0.8.4)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from catboost) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from matplotlib->catboost) (8.3.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages (from plotly->catboost) (8.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# I have renamed Udacity_MAILOUT_052018_TRAIN.csv and Udacity_MAILOUT_052018_TEST.csv for more readability\n",
    "# load data from csv files to make operation on them\n",
    "# missing values found in section of missing values and set it here for furure use\n",
    "missing_values = [\"X\", \"XX\"]\n",
    "\n",
    "#read csv file of mailout train with changing missing values to nan\n",
    "mailout_train = pd.read_csv('../data/mail_train.csv',sep=';',na_values=missing_values)\n",
    "#read csv file of mailout test with changing missing values to nan\n",
    "mailout_test = pd.read_csv('../data/mail_test.csv',sep=';',na_values=missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42957</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42958</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42960</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42961</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4\n",
       "0              NaN          NaN          NaN          NaN\n",
       "1              NaN          NaN          NaN          NaN\n",
       "2              NaN          NaN          NaN          NaN\n",
       "3              NaN          NaN          NaN          NaN\n",
       "4              NaN          NaN          NaN          NaN\n",
       "...            ...          ...          ...          ...\n",
       "42957          NaN          NaN          NaN          NaN\n",
       "42958          NaN          NaN          NaN          NaN\n",
       "42959          NaN          NaN          NaN          NaN\n",
       "42960          NaN          NaN          NaN          NaN\n",
       "42961          NaN          NaN          NaN          NaN\n",
       "\n",
       "[42962 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if mailout train has more than 80% missing values\n",
    "\n",
    "#sum of mailout_train null value\n",
    "mailout_train_null_sum=mailout_train.isnull().sum()\n",
    "\n",
    "#check percent of mailout train missing value\n",
    "missing_columns=mailout_train_null_sum/len(mailout_train)\n",
    "\n",
    "#list which features have missing value more than 80 percent\n",
    "missing_percent=0.80\n",
    "mailout_train[missing_columns[missing_columns > missing_percent].index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42829</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42830</th>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42831</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42832</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42833 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4\n",
       "0              NaN          NaN          NaN          NaN\n",
       "1              NaN          NaN          NaN          NaN\n",
       "2              NaN          NaN          NaN          NaN\n",
       "3              NaN          NaN          NaN          NaN\n",
       "4              NaN          NaN          NaN          NaN\n",
       "...            ...          ...          ...          ...\n",
       "42828          NaN          NaN          NaN          NaN\n",
       "42829          NaN          NaN          NaN          NaN\n",
       "42830         14.0         17.0          NaN          NaN\n",
       "42831          NaN          NaN          NaN          NaN\n",
       "42832          NaN          NaN          NaN          NaN\n",
       "\n",
       "[42833 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if mailout test has more than 80% missing values\n",
    "\n",
    "#sum of mailout_test null value\n",
    "mailout_test_null_sum=mailout_test.isnull().sum()\n",
    "\n",
    "#check percent of mailout test missing value\n",
    "missing_columns=mailout_test_null_sum/len(mailout_test)\n",
    "\n",
    "#list which features have missing value more than 80 percent\n",
    "missing_percent=0.80\n",
    "mailout_test[missing_columns[missing_columns > missing_percent].index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train['ALTER_KIND1']=mailout_train['ALTER_KIND1'].fillna(mailout_train['ALTER_KIND1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train['ALTER_KIND2']=mailout_train['ALTER_KIND2'].fillna(mailout_train['ALTER_KIND2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train['ALTER_KIND3']=mailout_train['ALTER_KIND3'].fillna(mailout_train['ALTER_KIND3'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train['ALTER_KIND4']=mailout_train['ALTER_KIND1'].fillna(mailout_train['ALTER_KIND4'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test['ALTER_KIND1']=mailout_test['ALTER_KIND1'].fillna(mailout_test['ALTER_KIND1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test['ALTER_KIND2']=mailout_test['ALTER_KIND2'].fillna(mailout_test['ALTER_KIND2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test['ALTER_KIND3']=mailout_test['ALTER_KIND3'].fillna(mailout_test['ALTER_KIND3'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test['ALTER_KIND4']=mailout_test['ALTER_KIND1'].fillna(mailout_test['ALTER_KIND4'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#I have renamed DIAS Attributes - Values 2017.xlsx to attributes\n",
    "# use openpyxl as an engine for reading xlsx files\n",
    "# as far as first row of attributes file is empty I set skip first row of attributes\n",
    "attributes = pd.read_excel('../data/attributes.xlsx', engine='openpyxl', skiprows = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first I have to list all values that recognize as unknow\n",
    "unkown_list= attributes['Meaning'].where(attributes['Meaning'].str.contains('unknown')).value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list that have unknown values of each attribute\n",
    "unkown_attributes_list = attributes[attributes['Meaning'].isin(unkown_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_to_nan(dataframe):\n",
    "   \n",
    "\n",
    "    # rotate through all of unkown attributes\n",
    "    for row in unkown_attributes_list.iterrows():\n",
    "        \n",
    "        # list the missed Value attributes from attributs excel file\n",
    "        missed_values_list = row[1]['Value']\n",
    "        \n",
    "        # list the attributes from attributs excel file\n",
    "        attribute = row[1]['Attribute']\n",
    "\n",
    "        # to pass if columns is not in dataframe\n",
    "        if attribute not in dataframe.columns:\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # to pass if value is integer\n",
    "        if isinstance(missed_values_list, int):\n",
    "            \n",
    "            dataframe[attribute].replace(missed_values_list, -1, inplace=True)\n",
    "         # to pass if value is String    \n",
    "        elif isinstance(missed_values_list, str):\n",
    "            \n",
    "            #parses the expression to make it as integer -1 with unkown\n",
    "            eval(\"dataframe[attribute].replace([\" + missed_values_list + \"], -1, inplace=True)\")\n",
    "            \n",
    "            dataframe[attribute].replace(missed_values_list, -1, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all mailout_train unkown value to fill with -1\n",
    "mailout_train = unknown_to_nan(mailout_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all mailout_train unkown value to fill with -1\n",
    "mailout_test = unknown_to_nan(mailout_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast datatype to float\n",
    "def values_type_to_float(dataframe,column):\n",
    "    \n",
    "    dataframe[column] = dataframe[column].astype('float')\n",
    "\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the value to numerical value  \n",
    "def values_map(dataframe,feature_old,feature_new,dictionary):\n",
    "    \n",
    "    dataframe[feature_new] = dataframe.loc[:, feature_old].map(dictionary)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make feature to have just year to mange it as numerical value\n",
    "def year_extractor(dataframe,column):\n",
    "    \n",
    "    dataframe['EINGEFUEGT_AM'] = pd.to_datetime(dataframe['EINGEFUEGT_AM']).dt.year\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_features(dataframe,features):\n",
    "\n",
    "    dataframe.drop(features, axis=1,inplace=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step by step cleaning and transforming process\n",
    "def clean_transform(dataframe,dataframe_name):\n",
    "    \n",
    "    #dataframe= values_replace(dataframe)\n",
    "    print(dataframe_name,'replace object values : done')\n",
    "    \n",
    "    dataframe= values_type_to_float(dataframe,'CAMEO_DEUG_2015')\n",
    "    print(dataframe_name,'cast values to float : done')\n",
    "    \n",
    "    dataframe= values_type_to_float(dataframe,'CAMEO_INTL_2015')\n",
    "    print(dataframe_name,'cast values to float : done')\n",
    "    \n",
    "\n",
    "    dataframe= values_map(dataframe,'OST_WEST_KZ','OST_WEST_KZ_E',{'W': 0, 'O': 1})\n",
    "    print(dataframe_name,'OST_WEST_KZ mapping : done')\n",
    "\n",
    "    \n",
    "    dataframe= year_extractor(dataframe,'EINGEFUEGT_AM')\n",
    "    print(dataframe_name,'EINGEFUEGT_AM year extraction : done')\n",
    "\n",
    "    \n",
    "    dataframe= drop_features(dataframe,['LNR', 'D19_LETZTER_KAUF_BRANCHE', 'OST_WEST_KZ', 'CAMEO_DEU_2015'])\n",
    "    print(dataframe_name,'drop some features : done')\n",
    "\n",
    "    \n",
    "    dataframe= values_map(dataframe,'PRAEGENDE_JUGENDJAHRE','PRAEGENDE_JUGENDJAHRE_DECADE',{1: 1, 2: 1, 3: 2, 4: 2, 5: 3, 6: 3, 7: 3, 8: 4, 9: 4, 10: 5,11: 5, 12: 5, 13: 5, 14: 6,15: 6, 0: np.nan})\n",
    "    print(dataframe_name,'PRAEGENDE_JUGENDJAHRE mapping : done')\n",
    "\n",
    "    \n",
    "    dataframe= values_map(dataframe,'PRAEGENDE_JUGENDJAHRE','PRAEGENDE_JUGENDJAHRE_MOVEMENT',{1: 0, 2: 1, 3: 0, 4: 1, 5: 0, 6: 1, 7: 1, 8: 0, 9: 1, 10: 0, 11: 1, 12: 0, 13: 1, 14: 0, 15: 1, 0: np.nan})\n",
    "    print(dataframe_name,'PRAEGENDE_JUGENDJAHRE mapping : done')\n",
    "\n",
    "    \n",
    "    dataframe= drop_features(dataframe,['PRAEGENDE_JUGENDJAHRE'])\n",
    "    print(dataframe_name,'drop PRAEGENDE_JUGENDJAHRE as an old feature : done')\n",
    "\n",
    "\n",
    "    print(dataframe_name,'cleaning and transforming finished')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mailout_train replace object values : done\n",
      "mailout_train cast values to float : done\n",
      "mailout_train cast values to float : done\n",
      "mailout_train OST_WEST_KZ mapping : done\n",
      "mailout_train EINGEFUEGT_AM year extraction : done\n",
      "mailout_train drop some features : done\n",
      "mailout_train PRAEGENDE_JUGENDJAHRE mapping : done\n",
      "mailout_train PRAEGENDE_JUGENDJAHRE mapping : done\n",
      "mailout_train drop PRAEGENDE_JUGENDJAHRE as an old feature : done\n",
      "mailout_train cleaning and transforming finished\n"
     ]
    }
   ],
   "source": [
    "#start the proccess of clean mailout_train dataframe from object datatype and transform some features to new feature\n",
    "mailout_train = clean_transform(mailout_train,'mailout_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mailout_test replace object values : done\n",
      "mailout_test cast values to float : done\n",
      "mailout_test cast values to float : done\n",
      "mailout_test OST_WEST_KZ mapping : done\n",
      "mailout_test EINGEFUEGT_AM year extraction : done\n",
      "mailout_test drop some features : done\n",
      "mailout_test PRAEGENDE_JUGENDJAHRE mapping : done\n",
      "mailout_test PRAEGENDE_JUGENDJAHRE mapping : done\n",
      "mailout_test drop PRAEGENDE_JUGENDJAHRE as an old feature : done\n",
      "mailout_test cleaning and transforming finished\n"
     ]
    }
   ],
   "source": [
    "#start the proccess of clean mailout_test dataframe from object datatype and transform some features to new feature\n",
    "mailout_test = clean_transform(mailout_test,'mailout_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we create our train and test dataframe and dataframe of actual output for test it with our model\n",
    "\n",
    "X_train = mailout_train\n",
    "\n",
    "X_test = mailout_test\n",
    "\n",
    "y_train = X_train['RESPONSE']\n",
    "\n",
    "\n",
    "X_train.drop(['RESPONSE'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test models with different classifier and score with Roc_Auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_compute_roc(classifier_model,classifier_name):\n",
    "    \n",
    "    #create pipline for models\n",
    "    pipeline = Pipeline([('impute', SimpleImputer(strategy= 'constant', fill_value = -1)),('scale', StandardScaler()),  (classifier_name, classifier_model)])\n",
    "    \n",
    "    #split X_train and y_train to create random train and test set\n",
    "    X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    #fit model to make prediction in next step\n",
    "    pipeline.fit(X_train_n, y_train_n)\n",
    "    \n",
    "    \n",
    "    #tpr as rue positive rate and fpr as False positive rate or sensitivity\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    # make a prediction of y_score with X_test_n\n",
    "    y_score_pred = pipeline.predict_proba(X_test_n)[:, 1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for n in range(2):\n",
    "        \n",
    "        fpr[n], tpr[n], _ = roc_curve(y_test_n, y_score_pred)\n",
    "        \n",
    "        roc_auc[n] = auc(fpr[n], tpr[n])\n",
    "    \n",
    "    \n",
    "    return roc_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "scores.append(['XGBClassifier',train_model_compute_roc(XGBClassifier(),'XGBClassifier')[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "scores.append(['LogisticRegression',train_model_compute_roc(LogisticRegression(),'Logistic Regression')[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(['RandomForestClassifier',train_model_compute_roc(RandomForestClassifier(),'RandomForestClassifier')[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(['LGBMClassifier',train_model_compute_roc(LGBMClassifier(),'LGBMClassifier')[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.046653\n",
      "0:\tlearn: 0.5985155\ttotal: 63.9ms\tremaining: 1m 3s\n",
      "1:\tlearn: 0.5180809\ttotal: 77ms\tremaining: 38.4s\n",
      "2:\tlearn: 0.4499156\ttotal: 91.7ms\tremaining: 30.5s\n",
      "3:\tlearn: 0.3923226\ttotal: 106ms\tremaining: 26.3s\n",
      "4:\tlearn: 0.3435625\ttotal: 122ms\tremaining: 24.3s\n",
      "5:\tlearn: 0.3023043\ttotal: 138ms\tremaining: 22.9s\n",
      "6:\tlearn: 0.2677020\ttotal: 152ms\tremaining: 21.6s\n",
      "7:\tlearn: 0.2386010\ttotal: 167ms\tremaining: 20.7s\n",
      "8:\tlearn: 0.2139100\ttotal: 183ms\tremaining: 20.2s\n",
      "9:\tlearn: 0.1932262\ttotal: 196ms\tremaining: 19.4s\n",
      "10:\tlearn: 0.1755524\ttotal: 210ms\tremaining: 18.9s\n",
      "11:\tlearn: 0.1606978\ttotal: 225ms\tremaining: 18.5s\n",
      "12:\tlearn: 0.1478688\ttotal: 240ms\tremaining: 18.2s\n",
      "13:\tlearn: 0.1369494\ttotal: 255ms\tremaining: 17.9s\n",
      "14:\tlearn: 0.1276947\ttotal: 271ms\tremaining: 17.8s\n",
      "15:\tlearn: 0.1197379\ttotal: 287ms\tremaining: 17.7s\n",
      "16:\tlearn: 0.1129477\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 0.1071335\ttotal: 315ms\tremaining: 17.2s\n",
      "18:\tlearn: 0.1020487\ttotal: 329ms\tremaining: 17s\n",
      "19:\tlearn: 0.0976574\ttotal: 343ms\tremaining: 16.8s\n",
      "20:\tlearn: 0.0938304\ttotal: 359ms\tremaining: 16.7s\n",
      "21:\tlearn: 0.0905293\ttotal: 373ms\tremaining: 16.6s\n",
      "22:\tlearn: 0.0861064\ttotal: 388ms\tremaining: 16.5s\n",
      "23:\tlearn: 0.0837073\ttotal: 402ms\tremaining: 16.3s\n",
      "24:\tlearn: 0.0803518\ttotal: 420ms\tremaining: 16.4s\n",
      "25:\tlearn: 0.0785809\ttotal: 435ms\tremaining: 16.3s\n",
      "26:\tlearn: 0.0759440\ttotal: 451ms\tremaining: 16.3s\n",
      "27:\tlearn: 0.0745105\ttotal: 468ms\tremaining: 16.2s\n",
      "28:\tlearn: 0.0732696\ttotal: 484ms\tremaining: 16.2s\n",
      "29:\tlearn: 0.0721429\ttotal: 499ms\tremaining: 16.1s\n",
      "30:\tlearn: 0.0712223\ttotal: 514ms\tremaining: 16.1s\n",
      "31:\tlearn: 0.0704373\ttotal: 526ms\tremaining: 15.9s\n",
      "32:\tlearn: 0.0697064\ttotal: 542ms\tremaining: 15.9s\n",
      "33:\tlearn: 0.0689818\ttotal: 558ms\tremaining: 15.8s\n",
      "34:\tlearn: 0.0680852\ttotal: 575ms\tremaining: 15.8s\n",
      "35:\tlearn: 0.0675085\ttotal: 589ms\tremaining: 15.8s\n",
      "36:\tlearn: 0.0670179\ttotal: 606ms\tremaining: 15.8s\n",
      "37:\tlearn: 0.0660154\ttotal: 620ms\tremaining: 15.7s\n",
      "38:\tlearn: 0.0656623\ttotal: 637ms\tremaining: 15.7s\n",
      "39:\tlearn: 0.0653332\ttotal: 652ms\tremaining: 15.7s\n",
      "40:\tlearn: 0.0647370\ttotal: 671ms\tremaining: 15.7s\n",
      "41:\tlearn: 0.0639742\ttotal: 688ms\tremaining: 15.7s\n",
      "42:\tlearn: 0.0637271\ttotal: 703ms\tremaining: 15.6s\n",
      "43:\tlearn: 0.0635276\ttotal: 718ms\tremaining: 15.6s\n",
      "44:\tlearn: 0.0633238\ttotal: 732ms\tremaining: 15.5s\n",
      "45:\tlearn: 0.0631511\ttotal: 748ms\tremaining: 15.5s\n",
      "46:\tlearn: 0.0625564\ttotal: 765ms\tremaining: 15.5s\n",
      "47:\tlearn: 0.0621508\ttotal: 780ms\tremaining: 15.5s\n",
      "48:\tlearn: 0.0619379\ttotal: 796ms\tremaining: 15.5s\n",
      "49:\tlearn: 0.0618214\ttotal: 810ms\tremaining: 15.4s\n",
      "50:\tlearn: 0.0617330\ttotal: 823ms\tremaining: 15.3s\n",
      "51:\tlearn: 0.0615326\ttotal: 837ms\tremaining: 15.3s\n",
      "52:\tlearn: 0.0611340\ttotal: 853ms\tremaining: 15.2s\n",
      "53:\tlearn: 0.0607469\ttotal: 870ms\tremaining: 15.2s\n",
      "54:\tlearn: 0.0605559\ttotal: 885ms\tremaining: 15.2s\n",
      "55:\tlearn: 0.0603800\ttotal: 901ms\tremaining: 15.2s\n",
      "56:\tlearn: 0.0602487\ttotal: 915ms\tremaining: 15.1s\n",
      "57:\tlearn: 0.0601966\ttotal: 930ms\tremaining: 15.1s\n",
      "58:\tlearn: 0.0600925\ttotal: 944ms\tremaining: 15.1s\n",
      "59:\tlearn: 0.0600404\ttotal: 958ms\tremaining: 15s\n",
      "60:\tlearn: 0.0599025\ttotal: 973ms\tremaining: 15s\n",
      "61:\tlearn: 0.0598492\ttotal: 988ms\tremaining: 14.9s\n",
      "62:\tlearn: 0.0595646\ttotal: 1s\tremaining: 14.9s\n",
      "63:\tlearn: 0.0593516\ttotal: 1.02s\tremaining: 14.9s\n",
      "64:\tlearn: 0.0593301\ttotal: 1.03s\tremaining: 14.8s\n",
      "65:\tlearn: 0.0593054\ttotal: 1.04s\tremaining: 14.8s\n",
      "66:\tlearn: 0.0592235\ttotal: 1.06s\tremaining: 14.8s\n",
      "67:\tlearn: 0.0591609\ttotal: 1.07s\tremaining: 14.7s\n",
      "68:\tlearn: 0.0590476\ttotal: 1.09s\tremaining: 14.7s\n",
      "69:\tlearn: 0.0590211\ttotal: 1.1s\tremaining: 14.6s\n",
      "70:\tlearn: 0.0590116\ttotal: 1.11s\tremaining: 14.6s\n",
      "71:\tlearn: 0.0587502\ttotal: 1.13s\tremaining: 14.6s\n",
      "72:\tlearn: 0.0587216\ttotal: 1.14s\tremaining: 14.5s\n",
      "73:\tlearn: 0.0586899\ttotal: 1.16s\tremaining: 14.5s\n",
      "74:\tlearn: 0.0586686\ttotal: 1.17s\tremaining: 14.5s\n",
      "75:\tlearn: 0.0586500\ttotal: 1.19s\tremaining: 14.4s\n",
      "76:\tlearn: 0.0586307\ttotal: 1.2s\tremaining: 14.4s\n",
      "77:\tlearn: 0.0585960\ttotal: 1.21s\tremaining: 14.3s\n",
      "78:\tlearn: 0.0585593\ttotal: 1.23s\tremaining: 14.3s\n",
      "79:\tlearn: 0.0584945\ttotal: 1.24s\tremaining: 14.3s\n",
      "80:\tlearn: 0.0584774\ttotal: 1.26s\tremaining: 14.3s\n",
      "81:\tlearn: 0.0582997\ttotal: 1.27s\tremaining: 14.2s\n",
      "82:\tlearn: 0.0582848\ttotal: 1.28s\tremaining: 14.2s\n",
      "83:\tlearn: 0.0582057\ttotal: 1.3s\tremaining: 14.2s\n",
      "84:\tlearn: 0.0581489\ttotal: 1.31s\tremaining: 14.1s\n",
      "85:\tlearn: 0.0579818\ttotal: 1.33s\tremaining: 14.1s\n",
      "86:\tlearn: 0.0579406\ttotal: 1.34s\tremaining: 14.1s\n",
      "87:\tlearn: 0.0578948\ttotal: 1.35s\tremaining: 14s\n",
      "88:\tlearn: 0.0578739\ttotal: 1.37s\tremaining: 14s\n",
      "89:\tlearn: 0.0578569\ttotal: 1.38s\tremaining: 14s\n",
      "90:\tlearn: 0.0578549\ttotal: 1.39s\tremaining: 13.9s\n",
      "91:\tlearn: 0.0577952\ttotal: 1.4s\tremaining: 13.9s\n",
      "92:\tlearn: 0.0577801\ttotal: 1.42s\tremaining: 13.8s\n",
      "93:\tlearn: 0.0577654\ttotal: 1.43s\tremaining: 13.8s\n",
      "94:\tlearn: 0.0577575\ttotal: 1.44s\tremaining: 13.8s\n",
      "95:\tlearn: 0.0577024\ttotal: 1.46s\tremaining: 13.7s\n",
      "96:\tlearn: 0.0576882\ttotal: 1.47s\tremaining: 13.7s\n",
      "97:\tlearn: 0.0576555\ttotal: 1.48s\tremaining: 13.7s\n",
      "98:\tlearn: 0.0575377\ttotal: 1.5s\tremaining: 13.7s\n",
      "99:\tlearn: 0.0574851\ttotal: 1.51s\tremaining: 13.6s\n",
      "100:\tlearn: 0.0573263\ttotal: 1.53s\tremaining: 13.6s\n",
      "101:\tlearn: 0.0572937\ttotal: 1.54s\tremaining: 13.6s\n",
      "102:\tlearn: 0.0572362\ttotal: 1.56s\tremaining: 13.6s\n",
      "103:\tlearn: 0.0571707\ttotal: 1.57s\tremaining: 13.5s\n",
      "104:\tlearn: 0.0570592\ttotal: 1.58s\tremaining: 13.5s\n",
      "105:\tlearn: 0.0570148\ttotal: 1.6s\tremaining: 13.5s\n",
      "106:\tlearn: 0.0570075\ttotal: 1.62s\tremaining: 13.5s\n",
      "107:\tlearn: 0.0569428\ttotal: 1.63s\tremaining: 13.5s\n",
      "108:\tlearn: 0.0569259\ttotal: 1.65s\tremaining: 13.5s\n",
      "109:\tlearn: 0.0569097\ttotal: 1.66s\tremaining: 13.4s\n",
      "110:\tlearn: 0.0568862\ttotal: 1.68s\tremaining: 13.4s\n",
      "111:\tlearn: 0.0568256\ttotal: 1.69s\tremaining: 13.4s\n",
      "112:\tlearn: 0.0568031\ttotal: 1.7s\tremaining: 13.4s\n",
      "113:\tlearn: 0.0567036\ttotal: 1.72s\tremaining: 13.4s\n",
      "114:\tlearn: 0.0566786\ttotal: 1.73s\tremaining: 13.3s\n",
      "115:\tlearn: 0.0566630\ttotal: 1.75s\tremaining: 13.3s\n",
      "116:\tlearn: 0.0566574\ttotal: 1.76s\tremaining: 13.3s\n",
      "117:\tlearn: 0.0565918\ttotal: 1.77s\tremaining: 13.3s\n",
      "118:\tlearn: 0.0565028\ttotal: 1.79s\tremaining: 13.3s\n",
      "119:\tlearn: 0.0564042\ttotal: 1.81s\tremaining: 13.2s\n",
      "120:\tlearn: 0.0563916\ttotal: 1.82s\tremaining: 13.2s\n",
      "121:\tlearn: 0.0563214\ttotal: 1.83s\tremaining: 13.2s\n",
      "122:\tlearn: 0.0562359\ttotal: 1.85s\tremaining: 13.2s\n",
      "123:\tlearn: 0.0561201\ttotal: 1.86s\tremaining: 13.2s\n",
      "124:\tlearn: 0.0561079\ttotal: 1.88s\tremaining: 13.1s\n",
      "125:\tlearn: 0.0560155\ttotal: 1.89s\tremaining: 13.1s\n",
      "126:\tlearn: 0.0559750\ttotal: 1.91s\tremaining: 13.1s\n",
      "127:\tlearn: 0.0559227\ttotal: 1.92s\tremaining: 13.1s\n",
      "128:\tlearn: 0.0557858\ttotal: 1.94s\tremaining: 13.1s\n",
      "129:\tlearn: 0.0557631\ttotal: 1.95s\tremaining: 13.1s\n",
      "130:\tlearn: 0.0557310\ttotal: 1.96s\tremaining: 13s\n",
      "131:\tlearn: 0.0556706\ttotal: 1.98s\tremaining: 13s\n",
      "132:\tlearn: 0.0556120\ttotal: 1.99s\tremaining: 13s\n",
      "133:\tlearn: 0.0555528\ttotal: 2.01s\tremaining: 13s\n",
      "134:\tlearn: 0.0554636\ttotal: 2.02s\tremaining: 13s\n",
      "135:\tlearn: 0.0553985\ttotal: 2.04s\tremaining: 13s\n",
      "136:\tlearn: 0.0553856\ttotal: 2.05s\tremaining: 12.9s\n",
      "137:\tlearn: 0.0553525\ttotal: 2.07s\tremaining: 12.9s\n",
      "138:\tlearn: 0.0552783\ttotal: 2.08s\tremaining: 12.9s\n",
      "139:\tlearn: 0.0552413\ttotal: 2.1s\tremaining: 12.9s\n",
      "140:\tlearn: 0.0551857\ttotal: 2.11s\tremaining: 12.9s\n",
      "141:\tlearn: 0.0551635\ttotal: 2.12s\tremaining: 12.8s\n",
      "142:\tlearn: 0.0550748\ttotal: 2.14s\tremaining: 12.8s\n",
      "143:\tlearn: 0.0549862\ttotal: 2.15s\tremaining: 12.8s\n",
      "144:\tlearn: 0.0549241\ttotal: 2.17s\tremaining: 12.8s\n",
      "145:\tlearn: 0.0548773\ttotal: 2.18s\tremaining: 12.8s\n",
      "146:\tlearn: 0.0547917\ttotal: 2.2s\tremaining: 12.8s\n",
      "147:\tlearn: 0.0547564\ttotal: 2.21s\tremaining: 12.7s\n",
      "148:\tlearn: 0.0547250\ttotal: 2.23s\tremaining: 12.7s\n",
      "149:\tlearn: 0.0546829\ttotal: 2.24s\tremaining: 12.7s\n",
      "150:\tlearn: 0.0545498\ttotal: 2.26s\tremaining: 12.7s\n",
      "151:\tlearn: 0.0545062\ttotal: 2.27s\tremaining: 12.7s\n",
      "152:\tlearn: 0.0544509\ttotal: 2.29s\tremaining: 12.7s\n",
      "153:\tlearn: 0.0544399\ttotal: 2.3s\tremaining: 12.6s\n",
      "154:\tlearn: 0.0543703\ttotal: 2.32s\tremaining: 12.6s\n",
      "155:\tlearn: 0.0543351\ttotal: 2.33s\tremaining: 12.6s\n",
      "156:\tlearn: 0.0542782\ttotal: 2.35s\tremaining: 12.6s\n",
      "157:\tlearn: 0.0542634\ttotal: 2.36s\tremaining: 12.6s\n",
      "158:\tlearn: 0.0542200\ttotal: 2.37s\tremaining: 12.5s\n",
      "159:\tlearn: 0.0541773\ttotal: 2.38s\tremaining: 12.5s\n",
      "160:\tlearn: 0.0541528\ttotal: 2.4s\tremaining: 12.5s\n",
      "161:\tlearn: 0.0541177\ttotal: 2.41s\tremaining: 12.5s\n",
      "162:\tlearn: 0.0541050\ttotal: 2.43s\tremaining: 12.5s\n",
      "163:\tlearn: 0.0540916\ttotal: 2.44s\tremaining: 12.5s\n",
      "164:\tlearn: 0.0540606\ttotal: 2.46s\tremaining: 12.4s\n",
      "165:\tlearn: 0.0539707\ttotal: 2.48s\tremaining: 12.4s\n",
      "166:\tlearn: 0.0539298\ttotal: 2.49s\tremaining: 12.4s\n",
      "167:\tlearn: 0.0538869\ttotal: 2.5s\tremaining: 12.4s\n",
      "168:\tlearn: 0.0538340\ttotal: 2.52s\tremaining: 12.4s\n",
      "169:\tlearn: 0.0538077\ttotal: 2.53s\tremaining: 12.4s\n",
      "170:\tlearn: 0.0537682\ttotal: 2.54s\tremaining: 12.3s\n",
      "171:\tlearn: 0.0537547\ttotal: 2.56s\tremaining: 12.3s\n",
      "172:\tlearn: 0.0537435\ttotal: 2.57s\tremaining: 12.3s\n",
      "173:\tlearn: 0.0537076\ttotal: 2.58s\tremaining: 12.3s\n",
      "174:\tlearn: 0.0536644\ttotal: 2.59s\tremaining: 12.2s\n",
      "175:\tlearn: 0.0536354\ttotal: 2.61s\tremaining: 12.2s\n",
      "176:\tlearn: 0.0536129\ttotal: 2.62s\tremaining: 12.2s\n",
      "177:\tlearn: 0.0535457\ttotal: 2.64s\tremaining: 12.2s\n",
      "178:\tlearn: 0.0534831\ttotal: 2.65s\tremaining: 12.2s\n",
      "179:\tlearn: 0.0534588\ttotal: 2.67s\tremaining: 12.2s\n",
      "180:\tlearn: 0.0534170\ttotal: 2.68s\tremaining: 12.1s\n",
      "181:\tlearn: 0.0533819\ttotal: 2.69s\tremaining: 12.1s\n",
      "182:\tlearn: 0.0533447\ttotal: 2.71s\tremaining: 12.1s\n",
      "183:\tlearn: 0.0532875\ttotal: 2.72s\tremaining: 12.1s\n",
      "184:\tlearn: 0.0532556\ttotal: 2.73s\tremaining: 12s\n",
      "185:\tlearn: 0.0532211\ttotal: 2.75s\tremaining: 12s\n",
      "186:\tlearn: 0.0531608\ttotal: 2.76s\tremaining: 12s\n",
      "187:\tlearn: 0.0531221\ttotal: 2.78s\tremaining: 12s\n",
      "188:\tlearn: 0.0530371\ttotal: 2.79s\tremaining: 12s\n",
      "189:\tlearn: 0.0530184\ttotal: 2.81s\tremaining: 12s\n",
      "190:\tlearn: 0.0529919\ttotal: 2.82s\tremaining: 11.9s\n",
      "191:\tlearn: 0.0529638\ttotal: 2.83s\tremaining: 11.9s\n",
      "192:\tlearn: 0.0529154\ttotal: 2.85s\tremaining: 11.9s\n",
      "193:\tlearn: 0.0528123\ttotal: 2.86s\tremaining: 11.9s\n",
      "194:\tlearn: 0.0527512\ttotal: 2.88s\tremaining: 11.9s\n",
      "195:\tlearn: 0.0526785\ttotal: 2.89s\tremaining: 11.9s\n",
      "196:\tlearn: 0.0526605\ttotal: 2.91s\tremaining: 11.8s\n",
      "197:\tlearn: 0.0525335\ttotal: 2.92s\tremaining: 11.8s\n",
      "198:\tlearn: 0.0524770\ttotal: 2.94s\tremaining: 11.8s\n",
      "199:\tlearn: 0.0524510\ttotal: 2.95s\tremaining: 11.8s\n",
      "200:\tlearn: 0.0524340\ttotal: 2.96s\tremaining: 11.8s\n",
      "201:\tlearn: 0.0523758\ttotal: 2.98s\tremaining: 11.8s\n",
      "202:\tlearn: 0.0523680\ttotal: 2.99s\tremaining: 11.7s\n",
      "203:\tlearn: 0.0522949\ttotal: 3.01s\tremaining: 11.7s\n",
      "204:\tlearn: 0.0522638\ttotal: 3.02s\tremaining: 11.7s\n",
      "205:\tlearn: 0.0522148\ttotal: 3.04s\tremaining: 11.7s\n",
      "206:\tlearn: 0.0521928\ttotal: 3.05s\tremaining: 11.7s\n",
      "207:\tlearn: 0.0521511\ttotal: 3.06s\tremaining: 11.7s\n",
      "208:\tlearn: 0.0520452\ttotal: 3.08s\tremaining: 11.7s\n",
      "209:\tlearn: 0.0519935\ttotal: 3.1s\tremaining: 11.6s\n",
      "210:\tlearn: 0.0519307\ttotal: 3.11s\tremaining: 11.6s\n",
      "211:\tlearn: 0.0519109\ttotal: 3.12s\tremaining: 11.6s\n",
      "212:\tlearn: 0.0518539\ttotal: 3.14s\tremaining: 11.6s\n",
      "213:\tlearn: 0.0518277\ttotal: 3.15s\tremaining: 11.6s\n",
      "214:\tlearn: 0.0517882\ttotal: 3.17s\tremaining: 11.6s\n",
      "215:\tlearn: 0.0517406\ttotal: 3.18s\tremaining: 11.6s\n",
      "216:\tlearn: 0.0516364\ttotal: 3.2s\tremaining: 11.6s\n",
      "217:\tlearn: 0.0515901\ttotal: 3.21s\tremaining: 11.5s\n",
      "218:\tlearn: 0.0515244\ttotal: 3.23s\tremaining: 11.5s\n",
      "219:\tlearn: 0.0514628\ttotal: 3.25s\tremaining: 11.5s\n",
      "220:\tlearn: 0.0514209\ttotal: 3.26s\tremaining: 11.5s\n",
      "221:\tlearn: 0.0513706\ttotal: 3.27s\tremaining: 11.5s\n",
      "222:\tlearn: 0.0512952\ttotal: 3.29s\tremaining: 11.5s\n",
      "223:\tlearn: 0.0512269\ttotal: 3.3s\tremaining: 11.4s\n",
      "224:\tlearn: 0.0511662\ttotal: 3.32s\tremaining: 11.4s\n",
      "225:\tlearn: 0.0511364\ttotal: 3.33s\tremaining: 11.4s\n",
      "226:\tlearn: 0.0510891\ttotal: 3.35s\tremaining: 11.4s\n",
      "227:\tlearn: 0.0509907\ttotal: 3.36s\tremaining: 11.4s\n",
      "228:\tlearn: 0.0509639\ttotal: 3.38s\tremaining: 11.4s\n",
      "229:\tlearn: 0.0508745\ttotal: 3.39s\tremaining: 11.4s\n",
      "230:\tlearn: 0.0508252\ttotal: 3.41s\tremaining: 11.3s\n",
      "231:\tlearn: 0.0508165\ttotal: 3.42s\tremaining: 11.3s\n",
      "232:\tlearn: 0.0507825\ttotal: 3.43s\tremaining: 11.3s\n",
      "233:\tlearn: 0.0507671\ttotal: 3.44s\tremaining: 11.3s\n",
      "234:\tlearn: 0.0506995\ttotal: 3.46s\tremaining: 11.3s\n",
      "235:\tlearn: 0.0506462\ttotal: 3.47s\tremaining: 11.2s\n",
      "236:\tlearn: 0.0505573\ttotal: 3.49s\tremaining: 11.2s\n",
      "237:\tlearn: 0.0505184\ttotal: 3.5s\tremaining: 11.2s\n",
      "238:\tlearn: 0.0504810\ttotal: 3.52s\tremaining: 11.2s\n",
      "239:\tlearn: 0.0504379\ttotal: 3.53s\tremaining: 11.2s\n",
      "240:\tlearn: 0.0503903\ttotal: 3.54s\tremaining: 11.2s\n",
      "241:\tlearn: 0.0503486\ttotal: 3.56s\tremaining: 11.1s\n",
      "242:\tlearn: 0.0502782\ttotal: 3.57s\tremaining: 11.1s\n",
      "243:\tlearn: 0.0502032\ttotal: 3.58s\tremaining: 11.1s\n",
      "244:\tlearn: 0.0501298\ttotal: 3.6s\tremaining: 11.1s\n",
      "245:\tlearn: 0.0500789\ttotal: 3.61s\tremaining: 11.1s\n",
      "246:\tlearn: 0.0500719\ttotal: 3.62s\tremaining: 11.1s\n",
      "247:\tlearn: 0.0500380\ttotal: 3.64s\tremaining: 11s\n",
      "248:\tlearn: 0.0500193\ttotal: 3.65s\tremaining: 11s\n",
      "249:\tlearn: 0.0500155\ttotal: 3.66s\tremaining: 11s\n",
      "250:\tlearn: 0.0499716\ttotal: 3.68s\tremaining: 11s\n",
      "251:\tlearn: 0.0499236\ttotal: 3.69s\tremaining: 11s\n",
      "252:\tlearn: 0.0499069\ttotal: 3.71s\tremaining: 10.9s\n",
      "253:\tlearn: 0.0498300\ttotal: 3.72s\tremaining: 10.9s\n",
      "254:\tlearn: 0.0498026\ttotal: 3.74s\tremaining: 10.9s\n",
      "255:\tlearn: 0.0497817\ttotal: 3.75s\tremaining: 10.9s\n",
      "256:\tlearn: 0.0497047\ttotal: 3.77s\tremaining: 10.9s\n",
      "257:\tlearn: 0.0496639\ttotal: 3.78s\tremaining: 10.9s\n",
      "258:\tlearn: 0.0496483\ttotal: 3.79s\tremaining: 10.8s\n",
      "259:\tlearn: 0.0496117\ttotal: 3.8s\tremaining: 10.8s\n",
      "260:\tlearn: 0.0495778\ttotal: 3.82s\tremaining: 10.8s\n",
      "261:\tlearn: 0.0494948\ttotal: 3.83s\tremaining: 10.8s\n",
      "262:\tlearn: 0.0494514\ttotal: 3.85s\tremaining: 10.8s\n",
      "263:\tlearn: 0.0493973\ttotal: 3.86s\tremaining: 10.8s\n",
      "264:\tlearn: 0.0493451\ttotal: 3.87s\tremaining: 10.7s\n",
      "265:\tlearn: 0.0492757\ttotal: 3.89s\tremaining: 10.7s\n",
      "266:\tlearn: 0.0492398\ttotal: 3.9s\tremaining: 10.7s\n",
      "267:\tlearn: 0.0491796\ttotal: 3.92s\tremaining: 10.7s\n",
      "268:\tlearn: 0.0491205\ttotal: 3.93s\tremaining: 10.7s\n",
      "269:\tlearn: 0.0490685\ttotal: 3.95s\tremaining: 10.7s\n",
      "270:\tlearn: 0.0490392\ttotal: 3.96s\tremaining: 10.7s\n",
      "271:\tlearn: 0.0489825\ttotal: 3.97s\tremaining: 10.6s\n",
      "272:\tlearn: 0.0488966\ttotal: 3.99s\tremaining: 10.6s\n",
      "273:\tlearn: 0.0488741\ttotal: 4s\tremaining: 10.6s\n",
      "274:\tlearn: 0.0487978\ttotal: 4.02s\tremaining: 10.6s\n",
      "275:\tlearn: 0.0487887\ttotal: 4.03s\tremaining: 10.6s\n",
      "276:\tlearn: 0.0487121\ttotal: 4.05s\tremaining: 10.6s\n",
      "277:\tlearn: 0.0486963\ttotal: 4.06s\tremaining: 10.5s\n",
      "278:\tlearn: 0.0486333\ttotal: 4.07s\tremaining: 10.5s\n",
      "279:\tlearn: 0.0485546\ttotal: 4.09s\tremaining: 10.5s\n",
      "280:\tlearn: 0.0485372\ttotal: 4.1s\tremaining: 10.5s\n",
      "281:\tlearn: 0.0484841\ttotal: 4.12s\tremaining: 10.5s\n",
      "282:\tlearn: 0.0484659\ttotal: 4.13s\tremaining: 10.5s\n",
      "283:\tlearn: 0.0484325\ttotal: 4.14s\tremaining: 10.4s\n",
      "284:\tlearn: 0.0483729\ttotal: 4.16s\tremaining: 10.4s\n",
      "285:\tlearn: 0.0483364\ttotal: 4.17s\tremaining: 10.4s\n",
      "286:\tlearn: 0.0483191\ttotal: 4.18s\tremaining: 10.4s\n",
      "287:\tlearn: 0.0483013\ttotal: 4.2s\tremaining: 10.4s\n",
      "288:\tlearn: 0.0482358\ttotal: 4.21s\tremaining: 10.4s\n",
      "289:\tlearn: 0.0481667\ttotal: 4.23s\tremaining: 10.3s\n",
      "290:\tlearn: 0.0481586\ttotal: 4.24s\tremaining: 10.3s\n",
      "291:\tlearn: 0.0481344\ttotal: 4.25s\tremaining: 10.3s\n",
      "292:\tlearn: 0.0480936\ttotal: 4.26s\tremaining: 10.3s\n",
      "293:\tlearn: 0.0480384\ttotal: 4.28s\tremaining: 10.3s\n",
      "294:\tlearn: 0.0480317\ttotal: 4.29s\tremaining: 10.3s\n",
      "295:\tlearn: 0.0479957\ttotal: 4.3s\tremaining: 10.2s\n",
      "296:\tlearn: 0.0479023\ttotal: 4.32s\tremaining: 10.2s\n",
      "297:\tlearn: 0.0478536\ttotal: 4.33s\tremaining: 10.2s\n",
      "298:\tlearn: 0.0478519\ttotal: 4.35s\tremaining: 10.2s\n",
      "299:\tlearn: 0.0478415\ttotal: 4.36s\tremaining: 10.2s\n",
      "300:\tlearn: 0.0477776\ttotal: 4.38s\tremaining: 10.2s\n",
      "301:\tlearn: 0.0477697\ttotal: 4.39s\tremaining: 10.1s\n",
      "302:\tlearn: 0.0477178\ttotal: 4.4s\tremaining: 10.1s\n",
      "303:\tlearn: 0.0476689\ttotal: 4.42s\tremaining: 10.1s\n",
      "304:\tlearn: 0.0475904\ttotal: 4.43s\tremaining: 10.1s\n",
      "305:\tlearn: 0.0475257\ttotal: 4.45s\tremaining: 10.1s\n",
      "306:\tlearn: 0.0474752\ttotal: 4.46s\tremaining: 10.1s\n",
      "307:\tlearn: 0.0473928\ttotal: 4.48s\tremaining: 10.1s\n",
      "308:\tlearn: 0.0473770\ttotal: 4.49s\tremaining: 10s\n",
      "309:\tlearn: 0.0472727\ttotal: 4.51s\tremaining: 10s\n",
      "310:\tlearn: 0.0472271\ttotal: 4.52s\tremaining: 10s\n",
      "311:\tlearn: 0.0471589\ttotal: 4.54s\tremaining: 10s\n",
      "312:\tlearn: 0.0470782\ttotal: 4.55s\tremaining: 9.99s\n",
      "313:\tlearn: 0.0469903\ttotal: 4.57s\tremaining: 9.98s\n",
      "314:\tlearn: 0.0469224\ttotal: 4.58s\tremaining: 9.96s\n",
      "315:\tlearn: 0.0468573\ttotal: 4.6s\tremaining: 9.95s\n",
      "316:\tlearn: 0.0468283\ttotal: 4.61s\tremaining: 9.93s\n",
      "317:\tlearn: 0.0467647\ttotal: 4.62s\tremaining: 9.92s\n",
      "318:\tlearn: 0.0467334\ttotal: 4.64s\tremaining: 9.9s\n",
      "319:\tlearn: 0.0466864\ttotal: 4.65s\tremaining: 9.88s\n",
      "320:\tlearn: 0.0466676\ttotal: 4.66s\tremaining: 9.87s\n",
      "321:\tlearn: 0.0465922\ttotal: 4.68s\tremaining: 9.85s\n",
      "322:\tlearn: 0.0465261\ttotal: 4.69s\tremaining: 9.84s\n",
      "323:\tlearn: 0.0464645\ttotal: 4.71s\tremaining: 9.82s\n",
      "324:\tlearn: 0.0464203\ttotal: 4.72s\tremaining: 9.8s\n",
      "325:\tlearn: 0.0464050\ttotal: 4.73s\tremaining: 9.78s\n",
      "326:\tlearn: 0.0463505\ttotal: 4.75s\tremaining: 9.77s\n",
      "327:\tlearn: 0.0463326\ttotal: 4.76s\tremaining: 9.75s\n",
      "328:\tlearn: 0.0462618\ttotal: 4.77s\tremaining: 9.74s\n",
      "329:\tlearn: 0.0461960\ttotal: 4.79s\tremaining: 9.72s\n",
      "330:\tlearn: 0.0461498\ttotal: 4.8s\tremaining: 9.71s\n",
      "331:\tlearn: 0.0460336\ttotal: 4.82s\tremaining: 9.7s\n",
      "332:\tlearn: 0.0459788\ttotal: 4.83s\tremaining: 9.68s\n",
      "333:\tlearn: 0.0459687\ttotal: 4.84s\tremaining: 9.66s\n",
      "334:\tlearn: 0.0459356\ttotal: 4.86s\tremaining: 9.64s\n",
      "335:\tlearn: 0.0459010\ttotal: 4.87s\tremaining: 9.63s\n",
      "336:\tlearn: 0.0458584\ttotal: 4.88s\tremaining: 9.61s\n",
      "337:\tlearn: 0.0457831\ttotal: 4.9s\tremaining: 9.59s\n",
      "338:\tlearn: 0.0456921\ttotal: 4.91s\tremaining: 9.58s\n",
      "339:\tlearn: 0.0456433\ttotal: 4.93s\tremaining: 9.57s\n",
      "340:\tlearn: 0.0456048\ttotal: 4.94s\tremaining: 9.55s\n",
      "341:\tlearn: 0.0455703\ttotal: 4.96s\tremaining: 9.54s\n",
      "342:\tlearn: 0.0455130\ttotal: 4.97s\tremaining: 9.52s\n",
      "343:\tlearn: 0.0454262\ttotal: 4.99s\tremaining: 9.51s\n",
      "344:\tlearn: 0.0453150\ttotal: 5s\tremaining: 9.5s\n",
      "345:\tlearn: 0.0452746\ttotal: 5.01s\tremaining: 9.48s\n",
      "346:\tlearn: 0.0452357\ttotal: 5.03s\tremaining: 9.46s\n",
      "347:\tlearn: 0.0451987\ttotal: 5.04s\tremaining: 9.44s\n",
      "348:\tlearn: 0.0451114\ttotal: 5.05s\tremaining: 9.43s\n",
      "349:\tlearn: 0.0450681\ttotal: 5.07s\tremaining: 9.41s\n",
      "350:\tlearn: 0.0449929\ttotal: 5.08s\tremaining: 9.4s\n",
      "351:\tlearn: 0.0449107\ttotal: 5.1s\tremaining: 9.38s\n",
      "352:\tlearn: 0.0448955\ttotal: 5.11s\tremaining: 9.37s\n",
      "353:\tlearn: 0.0448287\ttotal: 5.12s\tremaining: 9.35s\n",
      "354:\tlearn: 0.0447675\ttotal: 5.14s\tremaining: 9.34s\n",
      "355:\tlearn: 0.0446664\ttotal: 5.16s\tremaining: 9.33s\n",
      "356:\tlearn: 0.0446066\ttotal: 5.17s\tremaining: 9.32s\n",
      "357:\tlearn: 0.0446008\ttotal: 5.18s\tremaining: 9.3s\n",
      "358:\tlearn: 0.0445268\ttotal: 5.2s\tremaining: 9.29s\n",
      "359:\tlearn: 0.0444629\ttotal: 5.21s\tremaining: 9.27s\n",
      "360:\tlearn: 0.0444357\ttotal: 5.23s\tremaining: 9.26s\n",
      "361:\tlearn: 0.0443574\ttotal: 5.25s\tremaining: 9.25s\n",
      "362:\tlearn: 0.0443545\ttotal: 5.26s\tremaining: 9.23s\n",
      "363:\tlearn: 0.0443088\ttotal: 5.27s\tremaining: 9.21s\n",
      "364:\tlearn: 0.0442646\ttotal: 5.29s\tremaining: 9.2s\n",
      "365:\tlearn: 0.0441783\ttotal: 5.3s\tremaining: 9.19s\n",
      "366:\tlearn: 0.0441451\ttotal: 5.32s\tremaining: 9.18s\n",
      "367:\tlearn: 0.0441324\ttotal: 5.33s\tremaining: 9.16s\n",
      "368:\tlearn: 0.0440682\ttotal: 5.35s\tremaining: 9.14s\n",
      "369:\tlearn: 0.0440087\ttotal: 5.36s\tremaining: 9.13s\n",
      "370:\tlearn: 0.0439565\ttotal: 5.38s\tremaining: 9.11s\n",
      "371:\tlearn: 0.0439300\ttotal: 5.39s\tremaining: 9.1s\n",
      "372:\tlearn: 0.0438708\ttotal: 5.41s\tremaining: 9.09s\n",
      "373:\tlearn: 0.0438201\ttotal: 5.42s\tremaining: 9.07s\n",
      "374:\tlearn: 0.0437984\ttotal: 5.43s\tremaining: 9.06s\n",
      "375:\tlearn: 0.0437537\ttotal: 5.45s\tremaining: 9.04s\n",
      "376:\tlearn: 0.0436875\ttotal: 5.46s\tremaining: 9.02s\n",
      "377:\tlearn: 0.0436058\ttotal: 5.48s\tremaining: 9.01s\n",
      "378:\tlearn: 0.0435489\ttotal: 5.49s\tremaining: 9s\n",
      "379:\tlearn: 0.0434872\ttotal: 5.51s\tremaining: 8.98s\n",
      "380:\tlearn: 0.0433983\ttotal: 5.52s\tremaining: 8.97s\n",
      "381:\tlearn: 0.0433463\ttotal: 5.54s\tremaining: 8.96s\n",
      "382:\tlearn: 0.0432870\ttotal: 5.55s\tremaining: 8.95s\n",
      "383:\tlearn: 0.0432256\ttotal: 5.57s\tremaining: 8.93s\n",
      "384:\tlearn: 0.0431998\ttotal: 5.58s\tremaining: 8.92s\n",
      "385:\tlearn: 0.0431132\ttotal: 5.6s\tremaining: 8.9s\n",
      "386:\tlearn: 0.0430709\ttotal: 5.61s\tremaining: 8.88s\n",
      "387:\tlearn: 0.0429865\ttotal: 5.63s\tremaining: 8.87s\n",
      "388:\tlearn: 0.0429726\ttotal: 5.64s\tremaining: 8.86s\n",
      "389:\tlearn: 0.0429475\ttotal: 5.65s\tremaining: 8.84s\n",
      "390:\tlearn: 0.0428884\ttotal: 5.66s\tremaining: 8.82s\n",
      "391:\tlearn: 0.0427954\ttotal: 5.68s\tremaining: 8.81s\n",
      "392:\tlearn: 0.0427404\ttotal: 5.7s\tremaining: 8.8s\n",
      "393:\tlearn: 0.0427252\ttotal: 5.71s\tremaining: 8.78s\n",
      "394:\tlearn: 0.0426973\ttotal: 5.72s\tremaining: 8.76s\n",
      "395:\tlearn: 0.0426850\ttotal: 5.73s\tremaining: 8.74s\n",
      "396:\tlearn: 0.0425697\ttotal: 5.75s\tremaining: 8.73s\n",
      "397:\tlearn: 0.0425236\ttotal: 5.76s\tremaining: 8.71s\n",
      "398:\tlearn: 0.0424458\ttotal: 5.78s\tremaining: 8.71s\n",
      "399:\tlearn: 0.0424364\ttotal: 5.79s\tremaining: 8.69s\n",
      "400:\tlearn: 0.0423863\ttotal: 5.81s\tremaining: 8.67s\n",
      "401:\tlearn: 0.0423247\ttotal: 5.82s\tremaining: 8.66s\n",
      "402:\tlearn: 0.0422763\ttotal: 5.84s\tremaining: 8.65s\n",
      "403:\tlearn: 0.0422203\ttotal: 5.85s\tremaining: 8.63s\n",
      "404:\tlearn: 0.0422110\ttotal: 5.86s\tremaining: 8.61s\n",
      "405:\tlearn: 0.0421532\ttotal: 5.88s\tremaining: 8.6s\n",
      "406:\tlearn: 0.0420804\ttotal: 5.89s\tremaining: 8.59s\n",
      "407:\tlearn: 0.0420249\ttotal: 5.91s\tremaining: 8.57s\n",
      "408:\tlearn: 0.0419706\ttotal: 5.92s\tremaining: 8.56s\n",
      "409:\tlearn: 0.0418992\ttotal: 5.94s\tremaining: 8.54s\n",
      "410:\tlearn: 0.0418348\ttotal: 5.95s\tremaining: 8.53s\n",
      "411:\tlearn: 0.0417960\ttotal: 5.96s\tremaining: 8.51s\n",
      "412:\tlearn: 0.0417642\ttotal: 5.98s\tremaining: 8.5s\n",
      "413:\tlearn: 0.0417220\ttotal: 6s\tremaining: 8.48s\n",
      "414:\tlearn: 0.0416513\ttotal: 6.01s\tremaining: 8.47s\n",
      "415:\tlearn: 0.0415795\ttotal: 6.03s\tremaining: 8.46s\n",
      "416:\tlearn: 0.0415430\ttotal: 6.04s\tremaining: 8.44s\n",
      "417:\tlearn: 0.0414781\ttotal: 6.05s\tremaining: 8.43s\n",
      "418:\tlearn: 0.0414043\ttotal: 6.07s\tremaining: 8.42s\n",
      "419:\tlearn: 0.0413943\ttotal: 6.08s\tremaining: 8.4s\n",
      "420:\tlearn: 0.0413346\ttotal: 6.1s\tremaining: 8.38s\n",
      "421:\tlearn: 0.0413116\ttotal: 6.11s\tremaining: 8.37s\n",
      "422:\tlearn: 0.0412296\ttotal: 6.12s\tremaining: 8.35s\n",
      "423:\tlearn: 0.0412173\ttotal: 6.14s\tremaining: 8.34s\n",
      "424:\tlearn: 0.0411595\ttotal: 6.15s\tremaining: 8.32s\n",
      "425:\tlearn: 0.0411095\ttotal: 6.17s\tremaining: 8.31s\n",
      "426:\tlearn: 0.0410851\ttotal: 6.18s\tremaining: 8.29s\n",
      "427:\tlearn: 0.0410234\ttotal: 6.19s\tremaining: 8.28s\n",
      "428:\tlearn: 0.0409669\ttotal: 6.21s\tremaining: 8.26s\n",
      "429:\tlearn: 0.0409347\ttotal: 6.22s\tremaining: 8.25s\n",
      "430:\tlearn: 0.0408875\ttotal: 6.23s\tremaining: 8.23s\n",
      "431:\tlearn: 0.0408708\ttotal: 6.25s\tremaining: 8.21s\n",
      "432:\tlearn: 0.0408350\ttotal: 6.26s\tremaining: 8.2s\n",
      "433:\tlearn: 0.0408158\ttotal: 6.27s\tremaining: 8.18s\n",
      "434:\tlearn: 0.0407566\ttotal: 6.29s\tremaining: 8.17s\n",
      "435:\tlearn: 0.0407318\ttotal: 6.3s\tremaining: 8.15s\n",
      "436:\tlearn: 0.0407085\ttotal: 6.31s\tremaining: 8.13s\n",
      "437:\tlearn: 0.0406211\ttotal: 6.33s\tremaining: 8.12s\n",
      "438:\tlearn: 0.0405689\ttotal: 6.34s\tremaining: 8.11s\n",
      "439:\tlearn: 0.0404654\ttotal: 6.36s\tremaining: 8.09s\n",
      "440:\tlearn: 0.0404490\ttotal: 6.37s\tremaining: 8.08s\n",
      "441:\tlearn: 0.0404086\ttotal: 6.38s\tremaining: 8.06s\n",
      "442:\tlearn: 0.0403158\ttotal: 6.4s\tremaining: 8.05s\n",
      "443:\tlearn: 0.0402687\ttotal: 6.42s\tremaining: 8.04s\n",
      "444:\tlearn: 0.0402058\ttotal: 6.43s\tremaining: 8.02s\n",
      "445:\tlearn: 0.0401263\ttotal: 6.45s\tremaining: 8.01s\n",
      "446:\tlearn: 0.0401027\ttotal: 6.46s\tremaining: 7.99s\n",
      "447:\tlearn: 0.0400767\ttotal: 6.47s\tremaining: 7.98s\n",
      "448:\tlearn: 0.0400407\ttotal: 6.49s\tremaining: 7.96s\n",
      "449:\tlearn: 0.0400157\ttotal: 6.5s\tremaining: 7.95s\n",
      "450:\tlearn: 0.0399434\ttotal: 6.52s\tremaining: 7.93s\n",
      "451:\tlearn: 0.0398862\ttotal: 6.53s\tremaining: 7.92s\n",
      "452:\tlearn: 0.0398271\ttotal: 6.55s\tremaining: 7.91s\n",
      "453:\tlearn: 0.0397574\ttotal: 6.56s\tremaining: 7.89s\n",
      "454:\tlearn: 0.0397024\ttotal: 6.58s\tremaining: 7.88s\n",
      "455:\tlearn: 0.0396659\ttotal: 6.59s\tremaining: 7.87s\n",
      "456:\tlearn: 0.0396374\ttotal: 6.61s\tremaining: 7.85s\n",
      "457:\tlearn: 0.0396167\ttotal: 6.62s\tremaining: 7.83s\n",
      "458:\tlearn: 0.0395779\ttotal: 6.63s\tremaining: 7.82s\n",
      "459:\tlearn: 0.0395345\ttotal: 6.65s\tremaining: 7.8s\n",
      "460:\tlearn: 0.0395269\ttotal: 6.66s\tremaining: 7.79s\n",
      "461:\tlearn: 0.0394293\ttotal: 6.68s\tremaining: 7.78s\n",
      "462:\tlearn: 0.0393636\ttotal: 6.69s\tremaining: 7.76s\n",
      "463:\tlearn: 0.0393457\ttotal: 6.71s\tremaining: 7.75s\n",
      "464:\tlearn: 0.0393096\ttotal: 6.72s\tremaining: 7.73s\n",
      "465:\tlearn: 0.0392867\ttotal: 6.74s\tremaining: 7.72s\n",
      "466:\tlearn: 0.0392620\ttotal: 6.75s\tremaining: 7.7s\n",
      "467:\tlearn: 0.0391652\ttotal: 6.76s\tremaining: 7.69s\n",
      "468:\tlearn: 0.0391481\ttotal: 6.78s\tremaining: 7.67s\n",
      "469:\tlearn: 0.0390905\ttotal: 6.79s\tremaining: 7.66s\n",
      "470:\tlearn: 0.0390164\ttotal: 6.8s\tremaining: 7.64s\n",
      "471:\tlearn: 0.0389554\ttotal: 6.82s\tremaining: 7.63s\n",
      "472:\tlearn: 0.0388813\ttotal: 6.84s\tremaining: 7.62s\n",
      "473:\tlearn: 0.0388434\ttotal: 6.85s\tremaining: 7.6s\n",
      "474:\tlearn: 0.0387540\ttotal: 6.87s\tremaining: 7.59s\n",
      "475:\tlearn: 0.0387017\ttotal: 6.88s\tremaining: 7.58s\n",
      "476:\tlearn: 0.0386390\ttotal: 6.9s\tremaining: 7.56s\n",
      "477:\tlearn: 0.0386061\ttotal: 6.91s\tremaining: 7.55s\n",
      "478:\tlearn: 0.0385783\ttotal: 6.92s\tremaining: 7.53s\n",
      "479:\tlearn: 0.0385029\ttotal: 6.94s\tremaining: 7.52s\n",
      "480:\tlearn: 0.0384674\ttotal: 6.95s\tremaining: 7.5s\n",
      "481:\tlearn: 0.0384151\ttotal: 6.97s\tremaining: 7.49s\n",
      "482:\tlearn: 0.0383384\ttotal: 6.98s\tremaining: 7.47s\n",
      "483:\tlearn: 0.0382837\ttotal: 7s\tremaining: 7.46s\n",
      "484:\tlearn: 0.0382215\ttotal: 7.01s\tremaining: 7.45s\n",
      "485:\tlearn: 0.0381937\ttotal: 7.03s\tremaining: 7.43s\n",
      "486:\tlearn: 0.0381619\ttotal: 7.04s\tremaining: 7.42s\n",
      "487:\tlearn: 0.0381411\ttotal: 7.06s\tremaining: 7.4s\n",
      "488:\tlearn: 0.0381097\ttotal: 7.07s\tremaining: 7.39s\n",
      "489:\tlearn: 0.0380676\ttotal: 7.08s\tremaining: 7.37s\n",
      "490:\tlearn: 0.0379960\ttotal: 7.1s\tremaining: 7.36s\n",
      "491:\tlearn: 0.0379716\ttotal: 7.11s\tremaining: 7.34s\n",
      "492:\tlearn: 0.0379651\ttotal: 7.12s\tremaining: 7.33s\n",
      "493:\tlearn: 0.0379563\ttotal: 7.13s\tremaining: 7.31s\n",
      "494:\tlearn: 0.0379270\ttotal: 7.15s\tremaining: 7.29s\n",
      "495:\tlearn: 0.0378877\ttotal: 7.16s\tremaining: 7.28s\n",
      "496:\tlearn: 0.0378580\ttotal: 7.17s\tremaining: 7.26s\n",
      "497:\tlearn: 0.0378436\ttotal: 7.19s\tremaining: 7.24s\n",
      "498:\tlearn: 0.0378166\ttotal: 7.2s\tremaining: 7.23s\n",
      "499:\tlearn: 0.0377807\ttotal: 7.21s\tremaining: 7.21s\n",
      "500:\tlearn: 0.0377475\ttotal: 7.23s\tremaining: 7.2s\n",
      "501:\tlearn: 0.0377183\ttotal: 7.24s\tremaining: 7.18s\n",
      "502:\tlearn: 0.0377072\ttotal: 7.25s\tremaining: 7.17s\n",
      "503:\tlearn: 0.0376333\ttotal: 7.27s\tremaining: 7.15s\n",
      "504:\tlearn: 0.0375643\ttotal: 7.29s\tremaining: 7.14s\n",
      "505:\tlearn: 0.0375324\ttotal: 7.3s\tremaining: 7.13s\n",
      "506:\tlearn: 0.0374395\ttotal: 7.32s\tremaining: 7.12s\n",
      "507:\tlearn: 0.0374116\ttotal: 7.33s\tremaining: 7.1s\n",
      "508:\tlearn: 0.0373818\ttotal: 7.34s\tremaining: 7.08s\n",
      "509:\tlearn: 0.0373245\ttotal: 7.36s\tremaining: 7.07s\n",
      "510:\tlearn: 0.0372868\ttotal: 7.37s\tremaining: 7.06s\n",
      "511:\tlearn: 0.0372495\ttotal: 7.39s\tremaining: 7.04s\n",
      "512:\tlearn: 0.0372257\ttotal: 7.4s\tremaining: 7.03s\n",
      "513:\tlearn: 0.0371955\ttotal: 7.41s\tremaining: 7.01s\n",
      "514:\tlearn: 0.0371607\ttotal: 7.43s\tremaining: 7s\n",
      "515:\tlearn: 0.0371229\ttotal: 7.44s\tremaining: 6.98s\n",
      "516:\tlearn: 0.0370664\ttotal: 7.46s\tremaining: 6.97s\n",
      "517:\tlearn: 0.0370394\ttotal: 7.47s\tremaining: 6.95s\n",
      "518:\tlearn: 0.0369920\ttotal: 7.49s\tremaining: 6.94s\n",
      "519:\tlearn: 0.0369624\ttotal: 7.5s\tremaining: 6.92s\n",
      "520:\tlearn: 0.0369067\ttotal: 7.51s\tremaining: 6.91s\n",
      "521:\tlearn: 0.0368894\ttotal: 7.53s\tremaining: 6.89s\n",
      "522:\tlearn: 0.0368668\ttotal: 7.54s\tremaining: 6.88s\n",
      "523:\tlearn: 0.0368614\ttotal: 7.55s\tremaining: 6.86s\n",
      "524:\tlearn: 0.0368262\ttotal: 7.56s\tremaining: 6.84s\n",
      "525:\tlearn: 0.0367915\ttotal: 7.58s\tremaining: 6.83s\n",
      "526:\tlearn: 0.0367689\ttotal: 7.59s\tremaining: 6.81s\n",
      "527:\tlearn: 0.0367513\ttotal: 7.6s\tremaining: 6.8s\n",
      "528:\tlearn: 0.0366785\ttotal: 7.62s\tremaining: 6.78s\n",
      "529:\tlearn: 0.0366571\ttotal: 7.63s\tremaining: 6.77s\n",
      "530:\tlearn: 0.0366343\ttotal: 7.65s\tremaining: 6.75s\n",
      "531:\tlearn: 0.0365994\ttotal: 7.66s\tremaining: 6.74s\n",
      "532:\tlearn: 0.0365049\ttotal: 7.68s\tremaining: 6.73s\n",
      "533:\tlearn: 0.0364928\ttotal: 7.69s\tremaining: 6.71s\n",
      "534:\tlearn: 0.0364703\ttotal: 7.7s\tremaining: 6.69s\n",
      "535:\tlearn: 0.0363832\ttotal: 7.72s\tremaining: 6.68s\n",
      "536:\tlearn: 0.0363499\ttotal: 7.73s\tremaining: 6.67s\n",
      "537:\tlearn: 0.0362905\ttotal: 7.75s\tremaining: 6.65s\n",
      "538:\tlearn: 0.0362608\ttotal: 7.76s\tremaining: 6.64s\n",
      "539:\tlearn: 0.0362222\ttotal: 7.77s\tremaining: 6.62s\n",
      "540:\tlearn: 0.0362131\ttotal: 7.79s\tremaining: 6.61s\n",
      "541:\tlearn: 0.0361854\ttotal: 7.8s\tremaining: 6.59s\n",
      "542:\tlearn: 0.0361147\ttotal: 7.81s\tremaining: 6.58s\n",
      "543:\tlearn: 0.0360678\ttotal: 7.83s\tremaining: 6.56s\n",
      "544:\tlearn: 0.0360436\ttotal: 7.84s\tremaining: 6.55s\n",
      "545:\tlearn: 0.0359948\ttotal: 7.86s\tremaining: 6.53s\n",
      "546:\tlearn: 0.0359623\ttotal: 7.87s\tremaining: 6.52s\n",
      "547:\tlearn: 0.0359174\ttotal: 7.88s\tremaining: 6.5s\n",
      "548:\tlearn: 0.0358503\ttotal: 7.9s\tremaining: 6.49s\n",
      "549:\tlearn: 0.0358245\ttotal: 7.91s\tremaining: 6.47s\n",
      "550:\tlearn: 0.0358148\ttotal: 7.93s\tremaining: 6.46s\n",
      "551:\tlearn: 0.0357636\ttotal: 7.94s\tremaining: 6.45s\n",
      "552:\tlearn: 0.0357267\ttotal: 7.96s\tremaining: 6.43s\n",
      "553:\tlearn: 0.0357198\ttotal: 7.97s\tremaining: 6.42s\n",
      "554:\tlearn: 0.0356566\ttotal: 7.98s\tremaining: 6.4s\n",
      "555:\tlearn: 0.0356394\ttotal: 8s\tremaining: 6.38s\n",
      "556:\tlearn: 0.0356078\ttotal: 8.01s\tremaining: 6.37s\n",
      "557:\tlearn: 0.0355670\ttotal: 8.02s\tremaining: 6.36s\n",
      "558:\tlearn: 0.0355152\ttotal: 8.04s\tremaining: 6.34s\n",
      "559:\tlearn: 0.0354782\ttotal: 8.05s\tremaining: 6.33s\n",
      "560:\tlearn: 0.0353858\ttotal: 8.07s\tremaining: 6.31s\n",
      "561:\tlearn: 0.0353531\ttotal: 8.08s\tremaining: 6.3s\n",
      "562:\tlearn: 0.0353033\ttotal: 8.1s\tremaining: 6.29s\n",
      "563:\tlearn: 0.0352692\ttotal: 8.11s\tremaining: 6.27s\n",
      "564:\tlearn: 0.0352392\ttotal: 8.13s\tremaining: 6.26s\n",
      "565:\tlearn: 0.0352010\ttotal: 8.14s\tremaining: 6.24s\n",
      "566:\tlearn: 0.0351671\ttotal: 8.15s\tremaining: 6.23s\n",
      "567:\tlearn: 0.0351055\ttotal: 8.17s\tremaining: 6.21s\n",
      "568:\tlearn: 0.0350866\ttotal: 8.18s\tremaining: 6.2s\n",
      "569:\tlearn: 0.0350417\ttotal: 8.2s\tremaining: 6.18s\n",
      "570:\tlearn: 0.0350083\ttotal: 8.21s\tremaining: 6.17s\n",
      "571:\tlearn: 0.0349934\ttotal: 8.23s\tremaining: 6.16s\n",
      "572:\tlearn: 0.0349716\ttotal: 8.24s\tremaining: 6.14s\n",
      "573:\tlearn: 0.0349318\ttotal: 8.25s\tremaining: 6.13s\n",
      "574:\tlearn: 0.0348965\ttotal: 8.27s\tremaining: 6.11s\n",
      "575:\tlearn: 0.0348539\ttotal: 8.28s\tremaining: 6.1s\n",
      "576:\tlearn: 0.0347697\ttotal: 8.3s\tremaining: 6.08s\n",
      "577:\tlearn: 0.0346927\ttotal: 8.32s\tremaining: 6.07s\n",
      "578:\tlearn: 0.0346188\ttotal: 8.33s\tremaining: 6.06s\n",
      "579:\tlearn: 0.0345947\ttotal: 8.35s\tremaining: 6.04s\n",
      "580:\tlearn: 0.0345474\ttotal: 8.36s\tremaining: 6.03s\n",
      "581:\tlearn: 0.0344947\ttotal: 8.37s\tremaining: 6.01s\n",
      "582:\tlearn: 0.0343995\ttotal: 8.39s\tremaining: 6s\n",
      "583:\tlearn: 0.0343637\ttotal: 8.4s\tremaining: 5.99s\n",
      "584:\tlearn: 0.0343336\ttotal: 8.42s\tremaining: 5.97s\n",
      "585:\tlearn: 0.0343097\ttotal: 8.43s\tremaining: 5.96s\n",
      "586:\tlearn: 0.0342676\ttotal: 8.45s\tremaining: 5.94s\n",
      "587:\tlearn: 0.0342356\ttotal: 8.46s\tremaining: 5.93s\n",
      "588:\tlearn: 0.0342032\ttotal: 8.48s\tremaining: 5.92s\n",
      "589:\tlearn: 0.0341926\ttotal: 8.49s\tremaining: 5.9s\n",
      "590:\tlearn: 0.0341641\ttotal: 8.5s\tremaining: 5.88s\n",
      "591:\tlearn: 0.0341247\ttotal: 8.52s\tremaining: 5.87s\n",
      "592:\tlearn: 0.0340729\ttotal: 8.53s\tremaining: 5.86s\n",
      "593:\tlearn: 0.0340443\ttotal: 8.54s\tremaining: 5.84s\n",
      "594:\tlearn: 0.0340124\ttotal: 8.56s\tremaining: 5.83s\n",
      "595:\tlearn: 0.0339854\ttotal: 8.57s\tremaining: 5.81s\n",
      "596:\tlearn: 0.0339756\ttotal: 8.59s\tremaining: 5.79s\n",
      "597:\tlearn: 0.0339436\ttotal: 8.6s\tremaining: 5.78s\n",
      "598:\tlearn: 0.0339365\ttotal: 8.61s\tremaining: 5.76s\n",
      "599:\tlearn: 0.0338964\ttotal: 8.63s\tremaining: 5.75s\n",
      "600:\tlearn: 0.0338460\ttotal: 8.64s\tremaining: 5.74s\n",
      "601:\tlearn: 0.0338409\ttotal: 8.66s\tremaining: 5.72s\n",
      "602:\tlearn: 0.0337990\ttotal: 8.67s\tremaining: 5.71s\n",
      "603:\tlearn: 0.0337565\ttotal: 8.68s\tremaining: 5.69s\n",
      "604:\tlearn: 0.0337327\ttotal: 8.7s\tremaining: 5.68s\n",
      "605:\tlearn: 0.0336836\ttotal: 8.71s\tremaining: 5.66s\n",
      "606:\tlearn: 0.0336581\ttotal: 8.72s\tremaining: 5.65s\n",
      "607:\tlearn: 0.0336438\ttotal: 8.74s\tremaining: 5.63s\n",
      "608:\tlearn: 0.0336237\ttotal: 8.75s\tremaining: 5.62s\n",
      "609:\tlearn: 0.0335879\ttotal: 8.76s\tremaining: 5.6s\n",
      "610:\tlearn: 0.0335374\ttotal: 8.78s\tremaining: 5.59s\n",
      "611:\tlearn: 0.0334742\ttotal: 8.79s\tremaining: 5.58s\n",
      "612:\tlearn: 0.0334253\ttotal: 8.81s\tremaining: 5.56s\n",
      "613:\tlearn: 0.0334013\ttotal: 8.82s\tremaining: 5.55s\n",
      "614:\tlearn: 0.0333793\ttotal: 8.84s\tremaining: 5.53s\n",
      "615:\tlearn: 0.0333228\ttotal: 8.85s\tremaining: 5.52s\n",
      "616:\tlearn: 0.0332968\ttotal: 8.86s\tremaining: 5.5s\n",
      "617:\tlearn: 0.0332647\ttotal: 8.88s\tremaining: 5.49s\n",
      "618:\tlearn: 0.0332606\ttotal: 8.89s\tremaining: 5.47s\n",
      "619:\tlearn: 0.0332324\ttotal: 8.9s\tremaining: 5.46s\n",
      "620:\tlearn: 0.0331676\ttotal: 8.92s\tremaining: 5.44s\n",
      "621:\tlearn: 0.0331169\ttotal: 8.93s\tremaining: 5.43s\n",
      "622:\tlearn: 0.0330637\ttotal: 8.95s\tremaining: 5.42s\n",
      "623:\tlearn: 0.0330490\ttotal: 8.96s\tremaining: 5.4s\n",
      "624:\tlearn: 0.0330101\ttotal: 8.98s\tremaining: 5.38s\n",
      "625:\tlearn: 0.0329770\ttotal: 8.99s\tremaining: 5.37s\n",
      "626:\tlearn: 0.0329503\ttotal: 9s\tremaining: 5.36s\n",
      "627:\tlearn: 0.0328997\ttotal: 9.02s\tremaining: 5.34s\n",
      "628:\tlearn: 0.0328908\ttotal: 9.03s\tremaining: 5.33s\n",
      "629:\tlearn: 0.0328315\ttotal: 9.05s\tremaining: 5.31s\n",
      "630:\tlearn: 0.0327802\ttotal: 9.06s\tremaining: 5.3s\n",
      "631:\tlearn: 0.0327475\ttotal: 9.08s\tremaining: 5.29s\n",
      "632:\tlearn: 0.0326985\ttotal: 9.1s\tremaining: 5.27s\n",
      "633:\tlearn: 0.0326823\ttotal: 9.11s\tremaining: 5.26s\n",
      "634:\tlearn: 0.0326621\ttotal: 9.12s\tremaining: 5.24s\n",
      "635:\tlearn: 0.0326348\ttotal: 9.14s\tremaining: 5.23s\n",
      "636:\tlearn: 0.0326117\ttotal: 9.15s\tremaining: 5.21s\n",
      "637:\tlearn: 0.0325748\ttotal: 9.16s\tremaining: 5.2s\n",
      "638:\tlearn: 0.0325390\ttotal: 9.18s\tremaining: 5.18s\n",
      "639:\tlearn: 0.0324658\ttotal: 9.2s\tremaining: 5.17s\n",
      "640:\tlearn: 0.0324490\ttotal: 9.21s\tremaining: 5.16s\n",
      "641:\tlearn: 0.0324226\ttotal: 9.22s\tremaining: 5.14s\n",
      "642:\tlearn: 0.0323878\ttotal: 9.24s\tremaining: 5.13s\n",
      "643:\tlearn: 0.0323460\ttotal: 9.25s\tremaining: 5.11s\n",
      "644:\tlearn: 0.0322776\ttotal: 9.27s\tremaining: 5.1s\n",
      "645:\tlearn: 0.0322315\ttotal: 9.28s\tremaining: 5.09s\n",
      "646:\tlearn: 0.0321917\ttotal: 9.3s\tremaining: 5.07s\n",
      "647:\tlearn: 0.0321302\ttotal: 9.31s\tremaining: 5.06s\n",
      "648:\tlearn: 0.0320828\ttotal: 9.33s\tremaining: 5.04s\n",
      "649:\tlearn: 0.0320474\ttotal: 9.34s\tremaining: 5.03s\n",
      "650:\tlearn: 0.0320000\ttotal: 9.36s\tremaining: 5.02s\n",
      "651:\tlearn: 0.0319578\ttotal: 9.37s\tremaining: 5s\n",
      "652:\tlearn: 0.0318960\ttotal: 9.39s\tremaining: 4.99s\n",
      "653:\tlearn: 0.0318245\ttotal: 9.41s\tremaining: 4.98s\n",
      "654:\tlearn: 0.0317990\ttotal: 9.42s\tremaining: 4.96s\n",
      "655:\tlearn: 0.0317851\ttotal: 9.43s\tremaining: 4.95s\n",
      "656:\tlearn: 0.0317488\ttotal: 9.45s\tremaining: 4.93s\n",
      "657:\tlearn: 0.0317353\ttotal: 9.46s\tremaining: 4.92s\n",
      "658:\tlearn: 0.0316506\ttotal: 9.48s\tremaining: 4.9s\n",
      "659:\tlearn: 0.0316110\ttotal: 9.49s\tremaining: 4.89s\n",
      "660:\tlearn: 0.0315663\ttotal: 9.51s\tremaining: 4.88s\n",
      "661:\tlearn: 0.0315076\ttotal: 9.52s\tremaining: 4.86s\n",
      "662:\tlearn: 0.0314555\ttotal: 9.54s\tremaining: 4.85s\n",
      "663:\tlearn: 0.0313949\ttotal: 9.55s\tremaining: 4.83s\n",
      "664:\tlearn: 0.0313567\ttotal: 9.57s\tremaining: 4.82s\n",
      "665:\tlearn: 0.0312898\ttotal: 9.59s\tremaining: 4.81s\n",
      "666:\tlearn: 0.0312492\ttotal: 9.6s\tremaining: 4.79s\n",
      "667:\tlearn: 0.0312406\ttotal: 9.61s\tremaining: 4.78s\n",
      "668:\tlearn: 0.0312359\ttotal: 9.63s\tremaining: 4.76s\n",
      "669:\tlearn: 0.0312024\ttotal: 9.64s\tremaining: 4.75s\n",
      "670:\tlearn: 0.0311855\ttotal: 9.66s\tremaining: 4.74s\n",
      "671:\tlearn: 0.0311156\ttotal: 9.67s\tremaining: 4.72s\n",
      "672:\tlearn: 0.0310722\ttotal: 9.69s\tremaining: 4.71s\n",
      "673:\tlearn: 0.0310323\ttotal: 9.7s\tremaining: 4.69s\n",
      "674:\tlearn: 0.0309822\ttotal: 9.72s\tremaining: 4.68s\n",
      "675:\tlearn: 0.0309145\ttotal: 9.73s\tremaining: 4.67s\n",
      "676:\tlearn: 0.0308957\ttotal: 9.75s\tremaining: 4.65s\n",
      "677:\tlearn: 0.0308796\ttotal: 9.76s\tremaining: 4.64s\n",
      "678:\tlearn: 0.0308635\ttotal: 9.77s\tremaining: 4.62s\n",
      "679:\tlearn: 0.0308594\ttotal: 9.79s\tremaining: 4.6s\n",
      "680:\tlearn: 0.0308209\ttotal: 9.8s\tremaining: 4.59s\n",
      "681:\tlearn: 0.0307769\ttotal: 9.81s\tremaining: 4.58s\n",
      "682:\tlearn: 0.0307011\ttotal: 9.83s\tremaining: 4.56s\n",
      "683:\tlearn: 0.0306591\ttotal: 9.84s\tremaining: 4.55s\n",
      "684:\tlearn: 0.0306363\ttotal: 9.86s\tremaining: 4.53s\n",
      "685:\tlearn: 0.0305707\ttotal: 9.87s\tremaining: 4.52s\n",
      "686:\tlearn: 0.0305494\ttotal: 9.88s\tremaining: 4.5s\n",
      "687:\tlearn: 0.0305027\ttotal: 9.9s\tremaining: 4.49s\n",
      "688:\tlearn: 0.0304641\ttotal: 9.91s\tremaining: 4.47s\n",
      "689:\tlearn: 0.0304491\ttotal: 9.93s\tremaining: 4.46s\n",
      "690:\tlearn: 0.0304348\ttotal: 9.94s\tremaining: 4.44s\n",
      "691:\tlearn: 0.0303974\ttotal: 9.95s\tremaining: 4.43s\n",
      "692:\tlearn: 0.0303747\ttotal: 9.97s\tremaining: 4.42s\n",
      "693:\tlearn: 0.0303485\ttotal: 9.98s\tremaining: 4.4s\n",
      "694:\tlearn: 0.0303102\ttotal: 10s\tremaining: 4.39s\n",
      "695:\tlearn: 0.0302683\ttotal: 10s\tremaining: 4.37s\n",
      "696:\tlearn: 0.0302184\ttotal: 10s\tremaining: 4.36s\n",
      "697:\tlearn: 0.0301967\ttotal: 10s\tremaining: 4.34s\n",
      "698:\tlearn: 0.0301557\ttotal: 10.1s\tremaining: 4.33s\n",
      "699:\tlearn: 0.0301508\ttotal: 10.1s\tremaining: 4.32s\n",
      "700:\tlearn: 0.0301337\ttotal: 10.1s\tremaining: 4.3s\n",
      "701:\tlearn: 0.0301148\ttotal: 10.1s\tremaining: 4.29s\n",
      "702:\tlearn: 0.0300807\ttotal: 10.1s\tremaining: 4.27s\n",
      "703:\tlearn: 0.0300761\ttotal: 10.1s\tremaining: 4.26s\n",
      "704:\tlearn: 0.0300108\ttotal: 10.1s\tremaining: 4.24s\n",
      "705:\tlearn: 0.0299682\ttotal: 10.2s\tremaining: 4.23s\n",
      "706:\tlearn: 0.0299269\ttotal: 10.2s\tremaining: 4.21s\n",
      "707:\tlearn: 0.0299171\ttotal: 10.2s\tremaining: 4.2s\n",
      "708:\tlearn: 0.0298997\ttotal: 10.2s\tremaining: 4.19s\n",
      "709:\tlearn: 0.0298697\ttotal: 10.2s\tremaining: 4.17s\n",
      "710:\tlearn: 0.0298202\ttotal: 10.2s\tremaining: 4.16s\n",
      "711:\tlearn: 0.0297901\ttotal: 10.2s\tremaining: 4.14s\n",
      "712:\tlearn: 0.0297362\ttotal: 10.3s\tremaining: 4.13s\n",
      "713:\tlearn: 0.0297235\ttotal: 10.3s\tremaining: 4.12s\n",
      "714:\tlearn: 0.0296983\ttotal: 10.3s\tremaining: 4.1s\n",
      "715:\tlearn: 0.0296915\ttotal: 10.3s\tremaining: 4.09s\n",
      "716:\tlearn: 0.0296706\ttotal: 10.3s\tremaining: 4.07s\n",
      "717:\tlearn: 0.0296595\ttotal: 10.3s\tremaining: 4.06s\n",
      "718:\tlearn: 0.0296198\ttotal: 10.3s\tremaining: 4.04s\n",
      "719:\tlearn: 0.0295647\ttotal: 10.4s\tremaining: 4.03s\n",
      "720:\tlearn: 0.0295536\ttotal: 10.4s\tremaining: 4.01s\n",
      "721:\tlearn: 0.0295299\ttotal: 10.4s\tremaining: 4s\n",
      "722:\tlearn: 0.0294925\ttotal: 10.4s\tremaining: 3.99s\n",
      "723:\tlearn: 0.0294438\ttotal: 10.4s\tremaining: 3.97s\n",
      "724:\tlearn: 0.0293977\ttotal: 10.4s\tremaining: 3.96s\n",
      "725:\tlearn: 0.0293664\ttotal: 10.4s\tremaining: 3.94s\n",
      "726:\tlearn: 0.0293387\ttotal: 10.5s\tremaining: 3.93s\n",
      "727:\tlearn: 0.0292892\ttotal: 10.5s\tremaining: 3.91s\n",
      "728:\tlearn: 0.0292409\ttotal: 10.5s\tremaining: 3.9s\n",
      "729:\tlearn: 0.0291891\ttotal: 10.5s\tremaining: 3.89s\n",
      "730:\tlearn: 0.0291597\ttotal: 10.5s\tremaining: 3.87s\n",
      "731:\tlearn: 0.0291364\ttotal: 10.5s\tremaining: 3.86s\n",
      "732:\tlearn: 0.0291014\ttotal: 10.6s\tremaining: 3.84s\n",
      "733:\tlearn: 0.0290693\ttotal: 10.6s\tremaining: 3.83s\n",
      "734:\tlearn: 0.0290381\ttotal: 10.6s\tremaining: 3.81s\n",
      "735:\tlearn: 0.0290320\ttotal: 10.6s\tremaining: 3.8s\n",
      "736:\tlearn: 0.0289885\ttotal: 10.6s\tremaining: 3.79s\n",
      "737:\tlearn: 0.0289360\ttotal: 10.6s\tremaining: 3.77s\n",
      "738:\tlearn: 0.0289027\ttotal: 10.6s\tremaining: 3.76s\n",
      "739:\tlearn: 0.0288847\ttotal: 10.7s\tremaining: 3.75s\n",
      "740:\tlearn: 0.0288607\ttotal: 10.7s\tremaining: 3.73s\n",
      "741:\tlearn: 0.0288520\ttotal: 10.7s\tremaining: 3.72s\n",
      "742:\tlearn: 0.0288015\ttotal: 10.7s\tremaining: 3.7s\n",
      "743:\tlearn: 0.0287844\ttotal: 10.7s\tremaining: 3.69s\n",
      "744:\tlearn: 0.0287440\ttotal: 10.7s\tremaining: 3.67s\n",
      "745:\tlearn: 0.0287286\ttotal: 10.7s\tremaining: 3.66s\n",
      "746:\tlearn: 0.0286863\ttotal: 10.8s\tremaining: 3.65s\n",
      "747:\tlearn: 0.0286541\ttotal: 10.8s\tremaining: 3.63s\n",
      "748:\tlearn: 0.0286138\ttotal: 10.8s\tremaining: 3.62s\n",
      "749:\tlearn: 0.0285712\ttotal: 10.8s\tremaining: 3.6s\n",
      "750:\tlearn: 0.0285394\ttotal: 10.8s\tremaining: 3.59s\n",
      "751:\tlearn: 0.0285342\ttotal: 10.8s\tremaining: 3.57s\n",
      "752:\tlearn: 0.0285220\ttotal: 10.9s\tremaining: 3.56s\n",
      "753:\tlearn: 0.0284701\ttotal: 10.9s\tremaining: 3.55s\n",
      "754:\tlearn: 0.0284410\ttotal: 10.9s\tremaining: 3.53s\n",
      "755:\tlearn: 0.0284149\ttotal: 10.9s\tremaining: 3.52s\n",
      "756:\tlearn: 0.0283834\ttotal: 10.9s\tremaining: 3.5s\n",
      "757:\tlearn: 0.0283719\ttotal: 10.9s\tremaining: 3.49s\n",
      "758:\tlearn: 0.0283254\ttotal: 10.9s\tremaining: 3.47s\n",
      "759:\tlearn: 0.0282917\ttotal: 11s\tremaining: 3.46s\n",
      "760:\tlearn: 0.0282634\ttotal: 11s\tremaining: 3.44s\n",
      "761:\tlearn: 0.0282523\ttotal: 11s\tremaining: 3.43s\n",
      "762:\tlearn: 0.0282436\ttotal: 11s\tremaining: 3.42s\n",
      "763:\tlearn: 0.0282184\ttotal: 11s\tremaining: 3.4s\n",
      "764:\tlearn: 0.0281822\ttotal: 11s\tremaining: 3.39s\n",
      "765:\tlearn: 0.0281432\ttotal: 11s\tremaining: 3.37s\n",
      "766:\tlearn: 0.0281037\ttotal: 11.1s\tremaining: 3.36s\n",
      "767:\tlearn: 0.0280878\ttotal: 11.1s\tremaining: 3.34s\n",
      "768:\tlearn: 0.0280824\ttotal: 11.1s\tremaining: 3.33s\n",
      "769:\tlearn: 0.0280562\ttotal: 11.1s\tremaining: 3.31s\n",
      "770:\tlearn: 0.0280444\ttotal: 11.1s\tremaining: 3.3s\n",
      "771:\tlearn: 0.0280154\ttotal: 11.1s\tremaining: 3.29s\n",
      "772:\tlearn: 0.0279678\ttotal: 11.1s\tremaining: 3.27s\n",
      "773:\tlearn: 0.0279574\ttotal: 11.2s\tremaining: 3.26s\n",
      "774:\tlearn: 0.0279328\ttotal: 11.2s\tremaining: 3.24s\n",
      "775:\tlearn: 0.0279278\ttotal: 11.2s\tremaining: 3.23s\n",
      "776:\tlearn: 0.0279071\ttotal: 11.2s\tremaining: 3.21s\n",
      "777:\tlearn: 0.0278981\ttotal: 11.2s\tremaining: 3.2s\n",
      "778:\tlearn: 0.0278487\ttotal: 11.2s\tremaining: 3.18s\n",
      "779:\tlearn: 0.0278392\ttotal: 11.2s\tremaining: 3.17s\n",
      "780:\tlearn: 0.0278224\ttotal: 11.2s\tremaining: 3.15s\n",
      "781:\tlearn: 0.0278019\ttotal: 11.3s\tremaining: 3.14s\n",
      "782:\tlearn: 0.0277848\ttotal: 11.3s\tremaining: 3.13s\n",
      "783:\tlearn: 0.0277422\ttotal: 11.3s\tremaining: 3.11s\n",
      "784:\tlearn: 0.0277078\ttotal: 11.3s\tremaining: 3.1s\n",
      "785:\tlearn: 0.0276487\ttotal: 11.3s\tremaining: 3.08s\n",
      "786:\tlearn: 0.0276304\ttotal: 11.3s\tremaining: 3.07s\n",
      "787:\tlearn: 0.0275784\ttotal: 11.4s\tremaining: 3.05s\n",
      "788:\tlearn: 0.0275487\ttotal: 11.4s\tremaining: 3.04s\n",
      "789:\tlearn: 0.0275200\ttotal: 11.4s\tremaining: 3.02s\n",
      "790:\tlearn: 0.0274858\ttotal: 11.4s\tremaining: 3.01s\n",
      "791:\tlearn: 0.0274701\ttotal: 11.4s\tremaining: 3s\n",
      "792:\tlearn: 0.0274297\ttotal: 11.4s\tremaining: 2.98s\n",
      "793:\tlearn: 0.0274068\ttotal: 11.4s\tremaining: 2.97s\n",
      "794:\tlearn: 0.0273967\ttotal: 11.5s\tremaining: 2.95s\n",
      "795:\tlearn: 0.0273535\ttotal: 11.5s\tremaining: 2.94s\n",
      "796:\tlearn: 0.0273054\ttotal: 11.5s\tremaining: 2.93s\n",
      "797:\tlearn: 0.0272896\ttotal: 11.5s\tremaining: 2.91s\n",
      "798:\tlearn: 0.0272687\ttotal: 11.5s\tremaining: 2.9s\n",
      "799:\tlearn: 0.0272243\ttotal: 11.5s\tremaining: 2.88s\n",
      "800:\tlearn: 0.0272145\ttotal: 11.5s\tremaining: 2.87s\n",
      "801:\tlearn: 0.0271861\ttotal: 11.6s\tremaining: 2.85s\n",
      "802:\tlearn: 0.0271802\ttotal: 11.6s\tremaining: 2.84s\n",
      "803:\tlearn: 0.0271778\ttotal: 11.6s\tremaining: 2.82s\n",
      "804:\tlearn: 0.0271352\ttotal: 11.6s\tremaining: 2.81s\n",
      "805:\tlearn: 0.0270689\ttotal: 11.6s\tremaining: 2.8s\n",
      "806:\tlearn: 0.0270222\ttotal: 11.6s\tremaining: 2.78s\n",
      "807:\tlearn: 0.0270020\ttotal: 11.6s\tremaining: 2.77s\n",
      "808:\tlearn: 0.0269704\ttotal: 11.7s\tremaining: 2.75s\n",
      "809:\tlearn: 0.0269197\ttotal: 11.7s\tremaining: 2.74s\n",
      "810:\tlearn: 0.0269068\ttotal: 11.7s\tremaining: 2.73s\n",
      "811:\tlearn: 0.0268949\ttotal: 11.7s\tremaining: 2.71s\n",
      "812:\tlearn: 0.0268687\ttotal: 11.7s\tremaining: 2.7s\n",
      "813:\tlearn: 0.0268572\ttotal: 11.7s\tremaining: 2.68s\n",
      "814:\tlearn: 0.0268247\ttotal: 11.8s\tremaining: 2.67s\n",
      "815:\tlearn: 0.0267926\ttotal: 11.8s\tremaining: 2.65s\n",
      "816:\tlearn: 0.0267717\ttotal: 11.8s\tremaining: 2.64s\n",
      "817:\tlearn: 0.0267341\ttotal: 11.8s\tremaining: 2.63s\n",
      "818:\tlearn: 0.0266919\ttotal: 11.8s\tremaining: 2.61s\n",
      "819:\tlearn: 0.0266666\ttotal: 11.8s\tremaining: 2.6s\n",
      "820:\tlearn: 0.0266582\ttotal: 11.8s\tremaining: 2.58s\n",
      "821:\tlearn: 0.0266160\ttotal: 11.9s\tremaining: 2.57s\n",
      "822:\tlearn: 0.0266067\ttotal: 11.9s\tremaining: 2.55s\n",
      "823:\tlearn: 0.0266016\ttotal: 11.9s\tremaining: 2.54s\n",
      "824:\tlearn: 0.0265838\ttotal: 11.9s\tremaining: 2.52s\n",
      "825:\tlearn: 0.0265637\ttotal: 11.9s\tremaining: 2.51s\n",
      "826:\tlearn: 0.0265353\ttotal: 11.9s\tremaining: 2.49s\n",
      "827:\tlearn: 0.0265306\ttotal: 11.9s\tremaining: 2.48s\n",
      "828:\tlearn: 0.0264945\ttotal: 12s\tremaining: 2.46s\n",
      "829:\tlearn: 0.0264865\ttotal: 12s\tremaining: 2.45s\n",
      "830:\tlearn: 0.0264445\ttotal: 12s\tremaining: 2.44s\n",
      "831:\tlearn: 0.0264021\ttotal: 12s\tremaining: 2.42s\n",
      "832:\tlearn: 0.0263769\ttotal: 12s\tremaining: 2.41s\n",
      "833:\tlearn: 0.0263577\ttotal: 12s\tremaining: 2.39s\n",
      "834:\tlearn: 0.0263078\ttotal: 12s\tremaining: 2.38s\n",
      "835:\tlearn: 0.0262999\ttotal: 12.1s\tremaining: 2.36s\n",
      "836:\tlearn: 0.0262506\ttotal: 12.1s\tremaining: 2.35s\n",
      "837:\tlearn: 0.0262393\ttotal: 12.1s\tremaining: 2.33s\n",
      "838:\tlearn: 0.0262116\ttotal: 12.1s\tremaining: 2.32s\n",
      "839:\tlearn: 0.0261922\ttotal: 12.1s\tremaining: 2.31s\n",
      "840:\tlearn: 0.0261521\ttotal: 12.1s\tremaining: 2.29s\n",
      "841:\tlearn: 0.0261195\ttotal: 12.1s\tremaining: 2.28s\n",
      "842:\tlearn: 0.0261129\ttotal: 12.2s\tremaining: 2.26s\n",
      "843:\tlearn: 0.0261067\ttotal: 12.2s\tremaining: 2.25s\n",
      "844:\tlearn: 0.0261000\ttotal: 12.2s\tremaining: 2.23s\n",
      "845:\tlearn: 0.0260618\ttotal: 12.2s\tremaining: 2.22s\n",
      "846:\tlearn: 0.0260326\ttotal: 12.2s\tremaining: 2.21s\n",
      "847:\tlearn: 0.0260172\ttotal: 12.2s\tremaining: 2.19s\n",
      "848:\tlearn: 0.0260025\ttotal: 12.2s\tremaining: 2.18s\n",
      "849:\tlearn: 0.0259685\ttotal: 12.3s\tremaining: 2.16s\n",
      "850:\tlearn: 0.0259256\ttotal: 12.3s\tremaining: 2.15s\n",
      "851:\tlearn: 0.0259175\ttotal: 12.3s\tremaining: 2.13s\n",
      "852:\tlearn: 0.0258847\ttotal: 12.3s\tremaining: 2.12s\n",
      "853:\tlearn: 0.0258569\ttotal: 12.3s\tremaining: 2.1s\n",
      "854:\tlearn: 0.0258137\ttotal: 12.3s\tremaining: 2.09s\n",
      "855:\tlearn: 0.0258025\ttotal: 12.3s\tremaining: 2.08s\n",
      "856:\tlearn: 0.0257871\ttotal: 12.4s\tremaining: 2.06s\n",
      "857:\tlearn: 0.0257665\ttotal: 12.4s\tremaining: 2.05s\n",
      "858:\tlearn: 0.0257644\ttotal: 12.4s\tremaining: 2.03s\n",
      "859:\tlearn: 0.0257516\ttotal: 12.4s\tremaining: 2.02s\n",
      "860:\tlearn: 0.0257319\ttotal: 12.4s\tremaining: 2s\n",
      "861:\tlearn: 0.0256918\ttotal: 12.4s\tremaining: 1.99s\n",
      "862:\tlearn: 0.0256895\ttotal: 12.4s\tremaining: 1.97s\n",
      "863:\tlearn: 0.0256805\ttotal: 12.5s\tremaining: 1.96s\n",
      "864:\tlearn: 0.0256541\ttotal: 12.5s\tremaining: 1.95s\n",
      "865:\tlearn: 0.0256441\ttotal: 12.5s\tremaining: 1.93s\n",
      "866:\tlearn: 0.0256037\ttotal: 12.5s\tremaining: 1.92s\n",
      "867:\tlearn: 0.0255522\ttotal: 12.5s\tremaining: 1.9s\n",
      "868:\tlearn: 0.0255157\ttotal: 12.5s\tremaining: 1.89s\n",
      "869:\tlearn: 0.0254766\ttotal: 12.5s\tremaining: 1.87s\n",
      "870:\tlearn: 0.0254266\ttotal: 12.6s\tremaining: 1.86s\n",
      "871:\tlearn: 0.0254112\ttotal: 12.6s\tremaining: 1.84s\n",
      "872:\tlearn: 0.0253727\ttotal: 12.6s\tremaining: 1.83s\n",
      "873:\tlearn: 0.0253629\ttotal: 12.6s\tremaining: 1.82s\n",
      "874:\tlearn: 0.0253394\ttotal: 12.6s\tremaining: 1.8s\n",
      "875:\tlearn: 0.0253183\ttotal: 12.6s\tremaining: 1.79s\n",
      "876:\tlearn: 0.0252732\ttotal: 12.6s\tremaining: 1.77s\n",
      "877:\tlearn: 0.0252374\ttotal: 12.7s\tremaining: 1.76s\n",
      "878:\tlearn: 0.0252076\ttotal: 12.7s\tremaining: 1.75s\n",
      "879:\tlearn: 0.0251716\ttotal: 12.7s\tremaining: 1.73s\n",
      "880:\tlearn: 0.0251308\ttotal: 12.7s\tremaining: 1.72s\n",
      "881:\tlearn: 0.0250670\ttotal: 12.7s\tremaining: 1.7s\n",
      "882:\tlearn: 0.0250524\ttotal: 12.7s\tremaining: 1.69s\n",
      "883:\tlearn: 0.0250107\ttotal: 12.8s\tremaining: 1.67s\n",
      "884:\tlearn: 0.0249838\ttotal: 12.8s\tremaining: 1.66s\n",
      "885:\tlearn: 0.0249341\ttotal: 12.8s\tremaining: 1.65s\n",
      "886:\tlearn: 0.0248833\ttotal: 12.8s\tremaining: 1.63s\n",
      "887:\tlearn: 0.0248679\ttotal: 12.8s\tremaining: 1.62s\n",
      "888:\tlearn: 0.0248518\ttotal: 12.8s\tremaining: 1.6s\n",
      "889:\tlearn: 0.0248066\ttotal: 12.9s\tremaining: 1.59s\n",
      "890:\tlearn: 0.0248034\ttotal: 12.9s\tremaining: 1.57s\n",
      "891:\tlearn: 0.0247997\ttotal: 12.9s\tremaining: 1.56s\n",
      "892:\tlearn: 0.0247807\ttotal: 12.9s\tremaining: 1.54s\n",
      "893:\tlearn: 0.0247503\ttotal: 12.9s\tremaining: 1.53s\n",
      "894:\tlearn: 0.0247423\ttotal: 12.9s\tremaining: 1.51s\n",
      "895:\tlearn: 0.0247324\ttotal: 12.9s\tremaining: 1.5s\n",
      "896:\tlearn: 0.0247133\ttotal: 12.9s\tremaining: 1.49s\n",
      "897:\tlearn: 0.0247083\ttotal: 13s\tremaining: 1.47s\n",
      "898:\tlearn: 0.0246985\ttotal: 13s\tremaining: 1.46s\n",
      "899:\tlearn: 0.0246897\ttotal: 13s\tremaining: 1.44s\n",
      "900:\tlearn: 0.0246429\ttotal: 13s\tremaining: 1.43s\n",
      "901:\tlearn: 0.0246219\ttotal: 13s\tremaining: 1.41s\n",
      "902:\tlearn: 0.0246102\ttotal: 13s\tremaining: 1.4s\n",
      "903:\tlearn: 0.0245822\ttotal: 13s\tremaining: 1.39s\n",
      "904:\tlearn: 0.0245755\ttotal: 13.1s\tremaining: 1.37s\n",
      "905:\tlearn: 0.0245467\ttotal: 13.1s\tremaining: 1.36s\n",
      "906:\tlearn: 0.0245335\ttotal: 13.1s\tremaining: 1.34s\n",
      "907:\tlearn: 0.0245281\ttotal: 13.1s\tremaining: 1.33s\n",
      "908:\tlearn: 0.0245191\ttotal: 13.1s\tremaining: 1.31s\n",
      "909:\tlearn: 0.0244978\ttotal: 13.1s\tremaining: 1.3s\n",
      "910:\tlearn: 0.0244878\ttotal: 13.1s\tremaining: 1.28s\n",
      "911:\tlearn: 0.0244726\ttotal: 13.2s\tremaining: 1.27s\n",
      "912:\tlearn: 0.0244632\ttotal: 13.2s\tremaining: 1.25s\n",
      "913:\tlearn: 0.0244513\ttotal: 13.2s\tremaining: 1.24s\n",
      "914:\tlearn: 0.0244354\ttotal: 13.2s\tremaining: 1.23s\n",
      "915:\tlearn: 0.0244110\ttotal: 13.2s\tremaining: 1.21s\n",
      "916:\tlearn: 0.0243827\ttotal: 13.2s\tremaining: 1.2s\n",
      "917:\tlearn: 0.0243620\ttotal: 13.2s\tremaining: 1.18s\n",
      "918:\tlearn: 0.0243561\ttotal: 13.3s\tremaining: 1.17s\n",
      "919:\tlearn: 0.0243446\ttotal: 13.3s\tremaining: 1.15s\n",
      "920:\tlearn: 0.0243253\ttotal: 13.3s\tremaining: 1.14s\n",
      "921:\tlearn: 0.0242968\ttotal: 13.3s\tremaining: 1.13s\n",
      "922:\tlearn: 0.0242656\ttotal: 13.3s\tremaining: 1.11s\n",
      "923:\tlearn: 0.0242416\ttotal: 13.3s\tremaining: 1.1s\n",
      "924:\tlearn: 0.0242145\ttotal: 13.3s\tremaining: 1.08s\n",
      "925:\tlearn: 0.0242012\ttotal: 13.4s\tremaining: 1.07s\n",
      "926:\tlearn: 0.0241986\ttotal: 13.4s\tremaining: 1.05s\n",
      "927:\tlearn: 0.0241698\ttotal: 13.4s\tremaining: 1.04s\n",
      "928:\tlearn: 0.0241383\ttotal: 13.4s\tremaining: 1.02s\n",
      "929:\tlearn: 0.0240816\ttotal: 13.4s\tremaining: 1.01s\n",
      "930:\tlearn: 0.0240531\ttotal: 13.4s\tremaining: 995ms\n",
      "931:\tlearn: 0.0240212\ttotal: 13.4s\tremaining: 981ms\n",
      "932:\tlearn: 0.0239946\ttotal: 13.5s\tremaining: 967ms\n",
      "933:\tlearn: 0.0239775\ttotal: 13.5s\tremaining: 952ms\n",
      "934:\tlearn: 0.0239587\ttotal: 13.5s\tremaining: 938ms\n",
      "935:\tlearn: 0.0239275\ttotal: 13.5s\tremaining: 923ms\n",
      "936:\tlearn: 0.0239156\ttotal: 13.5s\tremaining: 909ms\n",
      "937:\tlearn: 0.0239009\ttotal: 13.5s\tremaining: 895ms\n",
      "938:\tlearn: 0.0238749\ttotal: 13.5s\tremaining: 880ms\n",
      "939:\tlearn: 0.0238553\ttotal: 13.6s\tremaining: 866ms\n",
      "940:\tlearn: 0.0238053\ttotal: 13.6s\tremaining: 851ms\n",
      "941:\tlearn: 0.0237847\ttotal: 13.6s\tremaining: 837ms\n",
      "942:\tlearn: 0.0237349\ttotal: 13.6s\tremaining: 823ms\n",
      "943:\tlearn: 0.0237041\ttotal: 13.6s\tremaining: 808ms\n",
      "944:\tlearn: 0.0236643\ttotal: 13.6s\tremaining: 794ms\n",
      "945:\tlearn: 0.0236441\ttotal: 13.7s\tremaining: 780ms\n",
      "946:\tlearn: 0.0236174\ttotal: 13.7s\tremaining: 765ms\n",
      "947:\tlearn: 0.0235823\ttotal: 13.7s\tremaining: 751ms\n",
      "948:\tlearn: 0.0235500\ttotal: 13.7s\tremaining: 737ms\n",
      "949:\tlearn: 0.0235306\ttotal: 13.7s\tremaining: 722ms\n",
      "950:\tlearn: 0.0235253\ttotal: 13.7s\tremaining: 708ms\n",
      "951:\tlearn: 0.0234817\ttotal: 13.7s\tremaining: 693ms\n",
      "952:\tlearn: 0.0234738\ttotal: 13.8s\tremaining: 679ms\n",
      "953:\tlearn: 0.0234656\ttotal: 13.8s\tremaining: 664ms\n",
      "954:\tlearn: 0.0234528\ttotal: 13.8s\tremaining: 650ms\n",
      "955:\tlearn: 0.0234093\ttotal: 13.8s\tremaining: 635ms\n",
      "956:\tlearn: 0.0233663\ttotal: 13.8s\tremaining: 621ms\n",
      "957:\tlearn: 0.0233390\ttotal: 13.8s\tremaining: 607ms\n",
      "958:\tlearn: 0.0233052\ttotal: 13.9s\tremaining: 592ms\n",
      "959:\tlearn: 0.0232716\ttotal: 13.9s\tremaining: 578ms\n",
      "960:\tlearn: 0.0232530\ttotal: 13.9s\tremaining: 563ms\n",
      "961:\tlearn: 0.0232477\ttotal: 13.9s\tremaining: 549ms\n",
      "962:\tlearn: 0.0232190\ttotal: 13.9s\tremaining: 535ms\n",
      "963:\tlearn: 0.0232024\ttotal: 13.9s\tremaining: 520ms\n",
      "964:\tlearn: 0.0231757\ttotal: 13.9s\tremaining: 506ms\n",
      "965:\tlearn: 0.0231639\ttotal: 14s\tremaining: 491ms\n",
      "966:\tlearn: 0.0231226\ttotal: 14s\tremaining: 477ms\n",
      "967:\tlearn: 0.0230999\ttotal: 14s\tremaining: 462ms\n",
      "968:\tlearn: 0.0230706\ttotal: 14s\tremaining: 448ms\n",
      "969:\tlearn: 0.0230400\ttotal: 14s\tremaining: 434ms\n",
      "970:\tlearn: 0.0230302\ttotal: 14s\tremaining: 419ms\n",
      "971:\tlearn: 0.0229947\ttotal: 14s\tremaining: 405ms\n",
      "972:\tlearn: 0.0229730\ttotal: 14.1s\tremaining: 390ms\n",
      "973:\tlearn: 0.0229635\ttotal: 14.1s\tremaining: 376ms\n",
      "974:\tlearn: 0.0229605\ttotal: 14.1s\tremaining: 361ms\n",
      "975:\tlearn: 0.0229226\ttotal: 14.1s\tremaining: 347ms\n",
      "976:\tlearn: 0.0228949\ttotal: 14.1s\tremaining: 332ms\n",
      "977:\tlearn: 0.0228861\ttotal: 14.1s\tremaining: 318ms\n",
      "978:\tlearn: 0.0228396\ttotal: 14.1s\tremaining: 303ms\n",
      "979:\tlearn: 0.0228375\ttotal: 14.2s\tremaining: 289ms\n",
      "980:\tlearn: 0.0228158\ttotal: 14.2s\tremaining: 274ms\n",
      "981:\tlearn: 0.0228050\ttotal: 14.2s\tremaining: 260ms\n",
      "982:\tlearn: 0.0228037\ttotal: 14.2s\tremaining: 246ms\n",
      "983:\tlearn: 0.0228015\ttotal: 14.2s\tremaining: 231ms\n",
      "984:\tlearn: 0.0227597\ttotal: 14.2s\tremaining: 217ms\n",
      "985:\tlearn: 0.0227492\ttotal: 14.2s\tremaining: 202ms\n",
      "986:\tlearn: 0.0227199\ttotal: 14.3s\tremaining: 188ms\n",
      "987:\tlearn: 0.0227091\ttotal: 14.3s\tremaining: 173ms\n",
      "988:\tlearn: 0.0227041\ttotal: 14.3s\tremaining: 159ms\n",
      "989:\tlearn: 0.0226752\ttotal: 14.3s\tremaining: 144ms\n",
      "990:\tlearn: 0.0226563\ttotal: 14.3s\tremaining: 130ms\n",
      "991:\tlearn: 0.0226085\ttotal: 14.3s\tremaining: 116ms\n",
      "992:\tlearn: 0.0225866\ttotal: 14.3s\tremaining: 101ms\n",
      "993:\tlearn: 0.0225695\ttotal: 14.4s\tremaining: 86.7ms\n",
      "994:\tlearn: 0.0225560\ttotal: 14.4s\tremaining: 72.2ms\n",
      "995:\tlearn: 0.0225340\ttotal: 14.4s\tremaining: 57.8ms\n",
      "996:\tlearn: 0.0225037\ttotal: 14.4s\tremaining: 43.3ms\n",
      "997:\tlearn: 0.0224866\ttotal: 14.4s\tremaining: 28.9ms\n",
      "998:\tlearn: 0.0224821\ttotal: 14.4s\tremaining: 14.4ms\n",
      "999:\tlearn: 0.0224772\ttotal: 14.4s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "scores.append(['catboost',train_model_compute_roc(CatBoostClassifier(),'CatBoostClassifier')[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dataframe = pd.DataFrame(scores, columns = ['Name', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.708335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.700094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.638744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.730610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>catboost</td>\n",
       "      <td>0.757077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name     Score\n",
       "0           XGBClassifier  0.708335\n",
       "1      LogisticRegression  0.700094\n",
       "2  RandomForestClassifier  0.638744\n",
       "3          LGBMClassifier  0.730610\n",
       "4                catboost  0.757077"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayesian XGBClassifier tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define limit of bayesian hyper parameter\n",
    "bayesian_tunning_bounds = {\n",
    "    'learning_rate': (0.00, 1.0),\n",
    "    'n_estimators': (100, 110),\n",
    "    'max_depth': (3,10),\n",
    "    'gamma': (0, 1),\n",
    "    'subsample':(0.5,0.9),\n",
    "    'colsample':(0.5,0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=3\n",
    "scoring_metric=\"roc_auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBClassifier_optimization_function(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        gamma,\n",
    "                       subsample,\n",
    "                       colsample):\n",
    "\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "\n",
    "    classifier = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample=colsample,\n",
    "        eta=0.1,\n",
    "        eval_metric='auc')\n",
    "    return np.mean(cross_val_score(classifier, X_train, y_train, cv=cv, scoring=scoring_metric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_opt = BayesianOptimization(\n",
    "    f=XGBClassifier_optimization_function,\n",
    "    pbounds=bayesian_tunning_bounds,\n",
    "    random_state=1\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsample |   gamma   | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:43] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:47] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:50] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7465  \u001b[0m | \u001b[0m 0.6668  \u001b[0m | \u001b[0m 0.7203  \u001b[0m | \u001b[0m 0.000114\u001b[0m | \u001b[0m 5.116   \u001b[0m | \u001b[0m 101.5   \u001b[0m | \u001b[0m 0.5369  \u001b[0m |\n",
      "[20:23:55] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:24:07] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:24:20] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6582  \u001b[0m | \u001b[0m 0.5745  \u001b[0m | \u001b[0m 0.3456  \u001b[0m | \u001b[0m 0.3968  \u001b[0m | \u001b[0m 6.772   \u001b[0m | \u001b[0m 104.2   \u001b[0m | \u001b[0m 0.7741  \u001b[0m |\n",
      "[20:24:34] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:24:48] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:01] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7631  \u001b[0m | \u001b[95m 0.5818  \u001b[0m | \u001b[95m 0.8781  \u001b[0m | \u001b[95m 0.02739 \u001b[0m | \u001b[95m 7.693   \u001b[0m | \u001b[95m 104.2   \u001b[0m | \u001b[95m 0.7235  \u001b[0m |\n",
      "[20:25:14] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:30] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:45] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6412  \u001b[0m | \u001b[0m 0.5562  \u001b[0m | \u001b[0m 0.1981  \u001b[0m | \u001b[0m 0.8007  \u001b[0m | \u001b[0m 9.778   \u001b[0m | \u001b[0m 103.1   \u001b[0m | \u001b[0m 0.7769  \u001b[0m |\n",
      "[20:26:01] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:07] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:13] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7685  \u001b[0m | \u001b[95m 0.8506  \u001b[0m | \u001b[95m 0.8946  \u001b[0m | \u001b[95m 0.08504 \u001b[0m | \u001b[95m 3.273   \u001b[0m | \u001b[95m 101.7   \u001b[0m | \u001b[95m 0.8513  \u001b[0m |\n",
      "[20:26:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:32] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:46] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6142  \u001b[0m | \u001b[0m 0.5393  \u001b[0m | \u001b[0m 0.4211  \u001b[0m | \u001b[0m 0.9579  \u001b[0m | \u001b[0m 6.732   \u001b[0m | \u001b[0m 106.9   \u001b[0m | \u001b[0m 0.6262  \u001b[0m |\n",
      "[20:26:59] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:27:14] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:27:29] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 0.7746  \u001b[0m | \u001b[0m 0.8346  \u001b[0m | \u001b[0m 0.01829 \u001b[0m | \u001b[0m 8.251   \u001b[0m | \u001b[0m 109.9   \u001b[0m | \u001b[0m 0.7993  \u001b[0m |\n",
      "[20:27:46] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:00] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:13] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 0.7893  \u001b[0m | \u001b[0m 0.1032  \u001b[0m | \u001b[0m 6.135   \u001b[0m | \u001b[0m 109.1   \u001b[0m | \u001b[0m 0.6174  \u001b[0m |\n",
      "[20:28:27] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:39] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:51] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 0.6151  \u001b[0m | \u001b[0m 0.13    \u001b[0m | \u001b[0m 0.01937 \u001b[0m | \u001b[0m 7.752   \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 0.6062  \u001b[0m |\n",
      "[20:29:03] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:11] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6457  \u001b[0m | \u001b[0m 0.6966  \u001b[0m | \u001b[0m 0.05336 \u001b[0m | \u001b[0m 0.5741  \u001b[0m | \u001b[0m 4.027   \u001b[0m | \u001b[0m 105.9   \u001b[0m | \u001b[0m 0.7799  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:28] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:40] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:52] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6632  \u001b[0m | \u001b[0m 0.7246  \u001b[0m | \u001b[0m 0.3754  \u001b[0m | \u001b[0m 0.4789  \u001b[0m | \u001b[0m 6.929   \u001b[0m | \u001b[0m 101.4   \u001b[0m | \u001b[0m 0.7578  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:05] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:18] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:32] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6381  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 0.3184  \u001b[0m | \u001b[0m 0.6631  \u001b[0m | \u001b[0m 6.139   \u001b[0m | \u001b[0m 101.7   \u001b[0m | \u001b[0m 0.6212  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:46] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:52] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:58] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.8193  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.099   \u001b[0m | \u001b[0m 101.7   \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:04] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:20] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:36] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6243  \u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 0.1223  \u001b[0m | \u001b[0m 0.73    \u001b[0m | \u001b[0m 9.077   \u001b[0m | \u001b[0m 106.6   \u001b[0m | \u001b[0m 0.658   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:52] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:32:06] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:32:20] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.602   \u001b[0m | \u001b[0m 0.8667  \u001b[0m | \u001b[0m 0.09461 \u001b[0m | \u001b[0m 0.9866  \u001b[0m | \u001b[0m 9.629   \u001b[0m | \u001b[0m 100.1   \u001b[0m | \u001b[0m 0.6816  \u001b[0m |\n",
      "=================================================================================================\n",
      "CPU times: user 1h 9min 4s, sys: 7.02 s, total: 1h 9min 11s\n",
      "Wall time: 8min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#performing Bayesian optimization for 5 iterations with 10 steps of random exploration with an acquisition function of expected improvement\n",
    "XGBoost_opt.maximize(n_iter=5, init_points=10, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample': 0.8505556609184153, 'gamma': 0.8946066635038473, 'learning_rate': 0.08504421136977791, 'max_depth': 3.2733834826301766, 'n_estimators': 101.69830419564569, 'subsample': 0.8512570013717653}\n"
     ]
    }
   ],
   "source": [
    "#Extracting the best parameters for usage in kaggle model creation\n",
    "params=XGBoost_opt.max['params']\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the max_depth and n_estimator values from float to int\n",
    "params['max_depth']= int(params['max_depth'])\n",
    "params['n_estimators']=int(params['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Part 3: Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:34:43] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:34:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 366\n",
    "\n",
    "#Calculate Feature Importance\n",
    "model_features_importance = XGBClassifier( verbose = False).fit( X_train, y_train)\n",
    "features_importance = pd.DataFrame({'features':X_train.columns, 'importance' : model_features_importance.feature_importances_/ model_features_importance.feature_importances_.sum()}).sort_values(['importance'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the ftrain and test data based on the important features\n",
    "X_train_kahesh = X_train[features_importance['features'].head(number_of_features).to_list()]\n",
    "X_test_kahesh = X_test[features_importance['features'].head(number_of_features).to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_LNR= pd.read_csv('../data/mail_test.csv',sep=';',na_values=missing_values)\n",
    "mailout_test_LNR=unknown_to_nan(mailout_test_LNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:36:18] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"colsample\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:36:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#use the dictionaty with optimized parameters result of the BayesianOptimization\n",
    "kaggle_model = XGBClassifier(**params)\n",
    "\n",
    "\n",
    "\n",
    "#fit kaggle model with reduced x and y\n",
    "kaggle_model.fit(X_train_kahesh, y_train)\n",
    "\n",
    "y_sub = kaggle_model.predict_proba(X_test_kahesh)[:, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create submit file for kaggle\n",
    "submission = pd.DataFrame({'LNR': mailout_test_LNR['LNR'], 'RESPONSE': y_sub})\n",
    "#save dataframe to csv file for submit\n",
    "submission.to_csv('submission_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
